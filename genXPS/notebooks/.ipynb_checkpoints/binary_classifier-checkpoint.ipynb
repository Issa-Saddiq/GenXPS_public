{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import os \n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Device Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: Tesla T4\n",
      "Number of GPUs available: 1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Optionally, you can print more details about the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Still need to create binary label!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_label_maker(label):\n",
    "    if label[18] == 0:\n",
    "        aliphatic_ester = 0\n",
    "    else:\n",
    "        aliphatic_ester = 1\n",
    "    \n",
    "    return aliphatic_ester\n",
    "\n",
    "def apply_horizontal_shift(spectrum, max_shift):\n",
    "    '''\n",
    "    Applies a random horizontal shift to the entire spectrum sequence.\n",
    "    Args:\n",
    "        spectrum\n",
    "        max_shift: maximum number of indices by which the data can shift (set to zero for no shift allowed)\n",
    "    Returns:\n",
    "        shifted_spectrum\n",
    "    '''\n",
    "    shift = random.randint(-max_shift, max_shift)\n",
    "    # Create an array of zeros with the same length as the original spectrum\n",
    "    shifted_spectrum = np.zeros_like(spectrum)\n",
    "\n",
    "    if shift > 0:\n",
    "        # Shift to the right\n",
    "        shifted_spectrum[shift:] = spectrum[:-shift]\n",
    "    elif shift < 0:\n",
    "        # Shift to the left\n",
    "        shifted_spectrum[:shift] = spectrum[-shift:]\n",
    "    else:\n",
    "        # No shift, return the original spectrum\n",
    "        shifted_spectrum = spectrum.copy()\n",
    "\n",
    "    shifted_spectrum = shifted_spectrum[:len(spectrum)]\n",
    "    return shifted_spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spectrum shape = torch.Size([20000, 7001])\n",
      "label shape = torch.Size([20000])\n"
     ]
    }
   ],
   "source": [
    "max_shift = 10\n",
    "#core_range = x \n",
    "\n",
    "# prepare list of file paths for file handeling\n",
    "spectra_dir = Path('../data/synthetic_data_full/synthetic_spectra')\n",
    "labels_dir = Path('../data/synthetic_data_full/synthetic_labels')\n",
    "\n",
    "all_spectra = [spectra_dir / file for file in os.listdir(spectra_dir)]\n",
    "all_labels = [labels_dir / file for file in os.listdir(labels_dir)]\n",
    "\n",
    "#extracting synthetic spectrum data and converting to tensor\n",
    "all_spectra.sort(key=lambda x: int(x.stem.split('_')[1]))\n",
    "spectrum_list = []\n",
    "for spectra_path in all_spectra:\n",
    "    spectrum_df = pd.read_csv(spectra_path)\n",
    "    spectrum = spectrum_df.values.flatten()  # Convert DataFrame to 1D array\n",
    "    shifted_spectrum = apply_horizontal_shift(spectrum, max_shift)  # Apply the shift\n",
    "    spectrum_df = pd.DataFrame(shifted_spectrum)  # Ensure this DataFrame is not empty\n",
    "    spectrum_list.append(spectrum_df)\n",
    "\n",
    "spectrum_array = np.array(spectrum_list).squeeze()\n",
    "spectrum_tensor = torch.tensor(spectrum_array,dtype=torch.float32)\n",
    "\n",
    "#extracting synthetic label data and converting to tensor\n",
    "all_labels.sort(key=lambda x: int(x.stem.split('_')[1]))\n",
    "label_list = []\n",
    "for label_path in all_labels:\n",
    "    label_df = pd.read_csv(label_path)\n",
    "    label_list.append(label_df)\n",
    "\n",
    "label_array = np.array(label_list).squeeze()\n",
    "bin_label_array = np.array([binary_label_maker(i) for i in label_array])\n",
    "\n",
    "\n",
    "label_tensor = torch.tensor(bin_label_array,dtype=torch.float32)\n",
    "\n",
    "print(f'spectrum shape = {spectrum_tensor.shape}')\n",
    "print(f'label shape = {label_tensor.shape}')\n",
    "\n",
    "\n",
    "#split into traning/testing batches\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(spectrum_tensor, \n",
    "                                                    label_tensor, \n",
    "                                                    test_size=0.2, # 20% test, 80% train\n",
    "                                                    random_state=42) # make the random split reproducible\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)\n",
    "\n",
    "input_features = spectrum_tensor.shape[1]\n",
    "output_features= 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting Up Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Construct a model class that subclasses nn.Module\n",
    "class BinClassifierV1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 2. Create 4 nn.Linear layers capable of handling X and y input and output shapes\n",
    "        self.layer_1 = nn.Linear(in_features=input_features, out_features=400) # takes in input_features (X), produces 400 features\n",
    "        self.layer_2 = nn.Linear(in_features=400, out_features=200) # takes in 400 features, produces 200 features\n",
    "        self.layer_3 = nn.Linear(in_features=200, out_features=100) # takes in 200 features, produces 100 features\n",
    "        self.layer_4 = nn.Linear(in_features=100, out_features=output_features) # takes in 100 features, produces 1 feature\n",
    "    \n",
    "    # 3. Define a forward method containing the forward pass computation\n",
    "    def forward(self, x):\n",
    "        # Return the output of layer_4, a single feature, the same shape as y\n",
    "        return self.layer_4(self.layer_3(self.layer_2(self.layer_1(x)))) # computation goes through layer_1, layer_2, layer_3, then the output of layer_3 goes through layer_4\n",
    "\n",
    "# 4. Create an instance of the model and send it to target device\n",
    "model_0 = BinClassifierV1().to(device)\n",
    "model_0\n",
    "\n",
    "\n",
    "# loss_fn = nn.BCELoss() # BCELoss = no sigmoid built-in\n",
    "loss_fn = nn.BCEWithLogitsLoss() # BCEWithLogitsLoss = sigmoid built-in\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), \n",
    "                            lr=1e-6)\n",
    "\n",
    "# Calculate accuracy (a classification metric)\n",
    "def accuracy_fn(y_true, y_pred):\n",
    "    correct = torch.eq(y_true, y_pred).sum().item() # torch.eq() calculates where two tensors are equal\n",
    "    acc = (correct / len(y_pred)) * 100 \n",
    "    return acc\n",
    "\n",
    "# Create a list to store loss values\n",
    "loss_values = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.48951, Accuracy: 76.96% | Test loss: 0.48784, Test acc: 77.45%\n",
      "Epoch: 10 | Loss: 0.48950, Accuracy: 76.95% | Test loss: 0.48784, Test acc: 77.45%\n",
      "Epoch: 20 | Loss: 0.48950, Accuracy: 76.95% | Test loss: 0.48783, Test acc: 77.45%\n",
      "Epoch: 30 | Loss: 0.48949, Accuracy: 76.95% | Test loss: 0.48783, Test acc: 77.45%\n",
      "Epoch: 40 | Loss: 0.48948, Accuracy: 76.95% | Test loss: 0.48782, Test acc: 77.45%\n",
      "Epoch: 50 | Loss: 0.48948, Accuracy: 76.95% | Test loss: 0.48782, Test acc: 77.45%\n",
      "Epoch: 60 | Loss: 0.48947, Accuracy: 76.95% | Test loss: 0.48781, Test acc: 77.45%\n",
      "Epoch: 70 | Loss: 0.48947, Accuracy: 76.96% | Test loss: 0.48781, Test acc: 77.45%\n",
      "Epoch: 80 | Loss: 0.48946, Accuracy: 76.96% | Test loss: 0.48780, Test acc: 77.45%\n",
      "Epoch: 90 | Loss: 0.48945, Accuracy: 76.96% | Test loss: 0.48779, Test acc: 77.45%\n",
      "Epoch: 100 | Loss: 0.48945, Accuracy: 76.95% | Test loss: 0.48779, Test acc: 77.45%\n",
      "Epoch: 110 | Loss: 0.48944, Accuracy: 76.95% | Test loss: 0.48778, Test acc: 77.45%\n",
      "Epoch: 120 | Loss: 0.48943, Accuracy: 76.95% | Test loss: 0.48778, Test acc: 77.45%\n",
      "Epoch: 130 | Loss: 0.48943, Accuracy: 76.95% | Test loss: 0.48777, Test acc: 77.45%\n",
      "Epoch: 140 | Loss: 0.48942, Accuracy: 76.95% | Test loss: 0.48777, Test acc: 77.45%\n",
      "Epoch: 150 | Loss: 0.48942, Accuracy: 76.95% | Test loss: 0.48776, Test acc: 77.45%\n",
      "Epoch: 160 | Loss: 0.48941, Accuracy: 76.95% | Test loss: 0.48776, Test acc: 77.45%\n",
      "Epoch: 170 | Loss: 0.48940, Accuracy: 76.95% | Test loss: 0.48775, Test acc: 77.45%\n",
      "Epoch: 180 | Loss: 0.48940, Accuracy: 76.95% | Test loss: 0.48775, Test acc: 77.45%\n",
      "Epoch: 190 | Loss: 0.48939, Accuracy: 76.95% | Test loss: 0.48774, Test acc: 77.45%\n",
      "Epoch: 200 | Loss: 0.48938, Accuracy: 76.95% | Test loss: 0.48774, Test acc: 77.45%\n",
      "Epoch: 210 | Loss: 0.48938, Accuracy: 76.95% | Test loss: 0.48773, Test acc: 77.45%\n",
      "Epoch: 220 | Loss: 0.48937, Accuracy: 76.95% | Test loss: 0.48773, Test acc: 77.45%\n",
      "Epoch: 230 | Loss: 0.48937, Accuracy: 76.95% | Test loss: 0.48772, Test acc: 77.45%\n",
      "Epoch: 240 | Loss: 0.48936, Accuracy: 76.95% | Test loss: 0.48772, Test acc: 77.45%\n",
      "Epoch: 250 | Loss: 0.48935, Accuracy: 76.95% | Test loss: 0.48771, Test acc: 77.45%\n",
      "Epoch: 260 | Loss: 0.48935, Accuracy: 76.95% | Test loss: 0.48771, Test acc: 77.45%\n",
      "Epoch: 270 | Loss: 0.48934, Accuracy: 76.95% | Test loss: 0.48770, Test acc: 77.45%\n",
      "Epoch: 280 | Loss: 0.48933, Accuracy: 76.95% | Test loss: 0.48769, Test acc: 77.45%\n",
      "Epoch: 290 | Loss: 0.48933, Accuracy: 76.94% | Test loss: 0.48769, Test acc: 77.45%\n",
      "Epoch: 300 | Loss: 0.48932, Accuracy: 76.94% | Test loss: 0.48768, Test acc: 77.45%\n",
      "Epoch: 310 | Loss: 0.48932, Accuracy: 76.94% | Test loss: 0.48768, Test acc: 77.45%\n",
      "Epoch: 320 | Loss: 0.48931, Accuracy: 76.94% | Test loss: 0.48767, Test acc: 77.45%\n",
      "Epoch: 330 | Loss: 0.48930, Accuracy: 76.94% | Test loss: 0.48767, Test acc: 77.45%\n",
      "Epoch: 340 | Loss: 0.48930, Accuracy: 76.94% | Test loss: 0.48766, Test acc: 77.45%\n",
      "Epoch: 350 | Loss: 0.48929, Accuracy: 76.94% | Test loss: 0.48766, Test acc: 77.45%\n",
      "Epoch: 360 | Loss: 0.48928, Accuracy: 76.94% | Test loss: 0.48765, Test acc: 77.45%\n",
      "Epoch: 370 | Loss: 0.48928, Accuracy: 76.95% | Test loss: 0.48765, Test acc: 77.45%\n",
      "Epoch: 380 | Loss: 0.48927, Accuracy: 76.95% | Test loss: 0.48764, Test acc: 77.45%\n",
      "Epoch: 390 | Loss: 0.48927, Accuracy: 76.95% | Test loss: 0.48764, Test acc: 77.45%\n",
      "Epoch: 400 | Loss: 0.48926, Accuracy: 76.95% | Test loss: 0.48763, Test acc: 77.45%\n",
      "Epoch: 410 | Loss: 0.48925, Accuracy: 76.95% | Test loss: 0.48763, Test acc: 77.45%\n",
      "Epoch: 420 | Loss: 0.48925, Accuracy: 76.95% | Test loss: 0.48762, Test acc: 77.45%\n",
      "Epoch: 430 | Loss: 0.48924, Accuracy: 76.91% | Test loss: 0.48762, Test acc: 77.42%\n",
      "Epoch: 440 | Loss: 0.48923, Accuracy: 76.91% | Test loss: 0.48761, Test acc: 77.42%\n",
      "Epoch: 450 | Loss: 0.48923, Accuracy: 76.92% | Test loss: 0.48761, Test acc: 77.42%\n",
      "Epoch: 460 | Loss: 0.48922, Accuracy: 76.92% | Test loss: 0.48760, Test acc: 77.42%\n",
      "Epoch: 470 | Loss: 0.48922, Accuracy: 76.92% | Test loss: 0.48760, Test acc: 77.42%\n",
      "Epoch: 480 | Loss: 0.48921, Accuracy: 76.92% | Test loss: 0.48759, Test acc: 77.42%\n",
      "Epoch: 490 | Loss: 0.48920, Accuracy: 76.92% | Test loss: 0.48759, Test acc: 77.42%\n",
      "Epoch: 500 | Loss: 0.48920, Accuracy: 76.92% | Test loss: 0.48758, Test acc: 77.42%\n",
      "Epoch: 510 | Loss: 0.48919, Accuracy: 76.92% | Test loss: 0.48757, Test acc: 77.42%\n",
      "Epoch: 520 | Loss: 0.48919, Accuracy: 76.92% | Test loss: 0.48757, Test acc: 77.42%\n",
      "Epoch: 530 | Loss: 0.48918, Accuracy: 76.92% | Test loss: 0.48756, Test acc: 77.42%\n",
      "Epoch: 540 | Loss: 0.48917, Accuracy: 76.92% | Test loss: 0.48756, Test acc: 77.42%\n",
      "Epoch: 550 | Loss: 0.48917, Accuracy: 76.92% | Test loss: 0.48755, Test acc: 77.42%\n",
      "Epoch: 560 | Loss: 0.48916, Accuracy: 76.92% | Test loss: 0.48755, Test acc: 77.42%\n",
      "Epoch: 570 | Loss: 0.48915, Accuracy: 76.92% | Test loss: 0.48754, Test acc: 77.42%\n",
      "Epoch: 580 | Loss: 0.48915, Accuracy: 76.92% | Test loss: 0.48754, Test acc: 77.42%\n",
      "Epoch: 590 | Loss: 0.48914, Accuracy: 76.92% | Test loss: 0.48753, Test acc: 77.42%\n",
      "Epoch: 600 | Loss: 0.48914, Accuracy: 76.92% | Test loss: 0.48753, Test acc: 77.42%\n",
      "Epoch: 610 | Loss: 0.48913, Accuracy: 76.92% | Test loss: 0.48752, Test acc: 77.42%\n",
      "Epoch: 620 | Loss: 0.48912, Accuracy: 76.92% | Test loss: 0.48752, Test acc: 77.42%\n",
      "Epoch: 630 | Loss: 0.48912, Accuracy: 76.92% | Test loss: 0.48751, Test acc: 77.42%\n",
      "Epoch: 640 | Loss: 0.48911, Accuracy: 76.92% | Test loss: 0.48751, Test acc: 77.42%\n",
      "Epoch: 650 | Loss: 0.48911, Accuracy: 76.92% | Test loss: 0.48750, Test acc: 77.42%\n",
      "Epoch: 660 | Loss: 0.48910, Accuracy: 76.92% | Test loss: 0.48750, Test acc: 77.42%\n",
      "Epoch: 670 | Loss: 0.48909, Accuracy: 76.92% | Test loss: 0.48749, Test acc: 77.42%\n",
      "Epoch: 680 | Loss: 0.48909, Accuracy: 76.92% | Test loss: 0.48749, Test acc: 77.42%\n",
      "Epoch: 690 | Loss: 0.48908, Accuracy: 76.92% | Test loss: 0.48748, Test acc: 77.42%\n",
      "Epoch: 700 | Loss: 0.48907, Accuracy: 76.92% | Test loss: 0.48748, Test acc: 77.42%\n",
      "Epoch: 710 | Loss: 0.48907, Accuracy: 76.92% | Test loss: 0.48747, Test acc: 77.42%\n",
      "Epoch: 720 | Loss: 0.48906, Accuracy: 76.92% | Test loss: 0.48747, Test acc: 77.42%\n",
      "Epoch: 730 | Loss: 0.48906, Accuracy: 76.92% | Test loss: 0.48746, Test acc: 77.42%\n",
      "Epoch: 740 | Loss: 0.48905, Accuracy: 76.92% | Test loss: 0.48746, Test acc: 77.42%\n",
      "Epoch: 750 | Loss: 0.48904, Accuracy: 76.92% | Test loss: 0.48745, Test acc: 77.42%\n",
      "Epoch: 760 | Loss: 0.48904, Accuracy: 76.91% | Test loss: 0.48745, Test acc: 77.42%\n",
      "Epoch: 770 | Loss: 0.48903, Accuracy: 76.91% | Test loss: 0.48744, Test acc: 77.42%\n",
      "Epoch: 780 | Loss: 0.48903, Accuracy: 76.91% | Test loss: 0.48744, Test acc: 77.42%\n",
      "Epoch: 790 | Loss: 0.48902, Accuracy: 76.91% | Test loss: 0.48743, Test acc: 77.42%\n",
      "Epoch: 800 | Loss: 0.48901, Accuracy: 76.91% | Test loss: 0.48742, Test acc: 77.42%\n",
      "Epoch: 810 | Loss: 0.48901, Accuracy: 76.91% | Test loss: 0.48742, Test acc: 77.42%\n",
      "Epoch: 820 | Loss: 0.48900, Accuracy: 76.91% | Test loss: 0.48741, Test acc: 77.42%\n",
      "Epoch: 830 | Loss: 0.48900, Accuracy: 76.92% | Test loss: 0.48741, Test acc: 77.42%\n",
      "Epoch: 840 | Loss: 0.48899, Accuracy: 76.92% | Test loss: 0.48740, Test acc: 77.42%\n",
      "Epoch: 850 | Loss: 0.48898, Accuracy: 76.92% | Test loss: 0.48740, Test acc: 77.42%\n",
      "Epoch: 860 | Loss: 0.48898, Accuracy: 76.92% | Test loss: 0.48739, Test acc: 77.42%\n",
      "Epoch: 870 | Loss: 0.48897, Accuracy: 76.92% | Test loss: 0.48739, Test acc: 77.42%\n",
      "Epoch: 880 | Loss: 0.48897, Accuracy: 76.92% | Test loss: 0.48738, Test acc: 77.42%\n",
      "Epoch: 890 | Loss: 0.48896, Accuracy: 76.92% | Test loss: 0.48738, Test acc: 77.42%\n",
      "Epoch: 900 | Loss: 0.48895, Accuracy: 76.92% | Test loss: 0.48737, Test acc: 77.42%\n",
      "Epoch: 910 | Loss: 0.48895, Accuracy: 76.92% | Test loss: 0.48737, Test acc: 77.42%\n",
      "Epoch: 920 | Loss: 0.48894, Accuracy: 76.92% | Test loss: 0.48736, Test acc: 77.42%\n",
      "Epoch: 930 | Loss: 0.48894, Accuracy: 76.92% | Test loss: 0.48736, Test acc: 77.42%\n",
      "Epoch: 940 | Loss: 0.48893, Accuracy: 76.92% | Test loss: 0.48735, Test acc: 77.42%\n",
      "Epoch: 950 | Loss: 0.48892, Accuracy: 76.92% | Test loss: 0.48735, Test acc: 77.42%\n",
      "Epoch: 960 | Loss: 0.48892, Accuracy: 76.92% | Test loss: 0.48734, Test acc: 77.42%\n",
      "Epoch: 970 | Loss: 0.48891, Accuracy: 76.92% | Test loss: 0.48734, Test acc: 77.42%\n",
      "Epoch: 980 | Loss: 0.48891, Accuracy: 76.92% | Test loss: 0.48733, Test acc: 77.42%\n",
      "Epoch: 990 | Loss: 0.48890, Accuracy: 76.92% | Test loss: 0.48733, Test acc: 77.42%\n",
      "Epoch: 1000 | Loss: 0.48889, Accuracy: 76.92% | Test loss: 0.48732, Test acc: 77.42%\n",
      "Epoch: 1010 | Loss: 0.48889, Accuracy: 76.92% | Test loss: 0.48732, Test acc: 77.42%\n",
      "Epoch: 1020 | Loss: 0.48888, Accuracy: 76.92% | Test loss: 0.48731, Test acc: 77.42%\n",
      "Epoch: 1030 | Loss: 0.48888, Accuracy: 76.92% | Test loss: 0.48731, Test acc: 77.42%\n",
      "Epoch: 1040 | Loss: 0.48887, Accuracy: 76.92% | Test loss: 0.48730, Test acc: 77.42%\n",
      "Epoch: 1050 | Loss: 0.48886, Accuracy: 76.92% | Test loss: 0.48730, Test acc: 77.42%\n",
      "Epoch: 1060 | Loss: 0.48886, Accuracy: 76.93% | Test loss: 0.48729, Test acc: 77.42%\n",
      "Epoch: 1070 | Loss: 0.48885, Accuracy: 76.93% | Test loss: 0.48729, Test acc: 77.42%\n",
      "Epoch: 1080 | Loss: 0.48885, Accuracy: 76.93% | Test loss: 0.48728, Test acc: 77.45%\n",
      "Epoch: 1090 | Loss: 0.48884, Accuracy: 76.93% | Test loss: 0.48728, Test acc: 77.45%\n",
      "Epoch: 1100 | Loss: 0.48883, Accuracy: 76.93% | Test loss: 0.48727, Test acc: 77.45%\n",
      "Epoch: 1110 | Loss: 0.48883, Accuracy: 76.93% | Test loss: 0.48727, Test acc: 77.45%\n",
      "Epoch: 1120 | Loss: 0.48882, Accuracy: 76.93% | Test loss: 0.48726, Test acc: 77.45%\n",
      "Epoch: 1130 | Loss: 0.48881, Accuracy: 76.94% | Test loss: 0.48726, Test acc: 77.45%\n",
      "Epoch: 1140 | Loss: 0.48881, Accuracy: 76.94% | Test loss: 0.48725, Test acc: 77.45%\n",
      "Epoch: 1150 | Loss: 0.48880, Accuracy: 76.94% | Test loss: 0.48725, Test acc: 77.45%\n",
      "Epoch: 1160 | Loss: 0.48880, Accuracy: 76.94% | Test loss: 0.48724, Test acc: 77.45%\n",
      "Epoch: 1170 | Loss: 0.48879, Accuracy: 76.94% | Test loss: 0.48724, Test acc: 77.45%\n",
      "Epoch: 1180 | Loss: 0.48879, Accuracy: 76.93% | Test loss: 0.48723, Test acc: 77.45%\n",
      "Epoch: 1190 | Loss: 0.48878, Accuracy: 76.93% | Test loss: 0.48723, Test acc: 77.45%\n",
      "Epoch: 1200 | Loss: 0.48877, Accuracy: 76.93% | Test loss: 0.48722, Test acc: 77.45%\n",
      "Epoch: 1210 | Loss: 0.48877, Accuracy: 76.92% | Test loss: 0.48722, Test acc: 77.45%\n",
      "Epoch: 1220 | Loss: 0.48876, Accuracy: 76.92% | Test loss: 0.48721, Test acc: 77.45%\n",
      "Epoch: 1230 | Loss: 0.48876, Accuracy: 76.92% | Test loss: 0.48721, Test acc: 77.45%\n",
      "Epoch: 1240 | Loss: 0.48875, Accuracy: 76.92% | Test loss: 0.48720, Test acc: 77.42%\n",
      "Epoch: 1250 | Loss: 0.48874, Accuracy: 76.92% | Test loss: 0.48720, Test acc: 77.42%\n",
      "Epoch: 1260 | Loss: 0.48874, Accuracy: 76.92% | Test loss: 0.48719, Test acc: 77.42%\n",
      "Epoch: 1270 | Loss: 0.48873, Accuracy: 76.93% | Test loss: 0.48719, Test acc: 77.42%\n",
      "Epoch: 1280 | Loss: 0.48873, Accuracy: 76.94% | Test loss: 0.48718, Test acc: 77.42%\n",
      "Epoch: 1290 | Loss: 0.48872, Accuracy: 76.94% | Test loss: 0.48718, Test acc: 77.42%\n",
      "Epoch: 1300 | Loss: 0.48871, Accuracy: 76.94% | Test loss: 0.48717, Test acc: 77.42%\n",
      "Epoch: 1310 | Loss: 0.48871, Accuracy: 76.94% | Test loss: 0.48717, Test acc: 77.42%\n",
      "Epoch: 1320 | Loss: 0.48870, Accuracy: 76.95% | Test loss: 0.48716, Test acc: 77.42%\n",
      "Epoch: 1330 | Loss: 0.48870, Accuracy: 76.95% | Test loss: 0.48716, Test acc: 77.42%\n",
      "Epoch: 1340 | Loss: 0.48869, Accuracy: 76.95% | Test loss: 0.48715, Test acc: 77.42%\n",
      "Epoch: 1350 | Loss: 0.48868, Accuracy: 76.95% | Test loss: 0.48715, Test acc: 77.42%\n",
      "Epoch: 1360 | Loss: 0.48868, Accuracy: 76.95% | Test loss: 0.48714, Test acc: 77.42%\n",
      "Epoch: 1370 | Loss: 0.48867, Accuracy: 76.95% | Test loss: 0.48714, Test acc: 77.42%\n",
      "Epoch: 1380 | Loss: 0.48867, Accuracy: 76.95% | Test loss: 0.48713, Test acc: 77.42%\n",
      "Epoch: 1390 | Loss: 0.48866, Accuracy: 76.95% | Test loss: 0.48713, Test acc: 77.40%\n",
      "Epoch: 1400 | Loss: 0.48865, Accuracy: 76.95% | Test loss: 0.48712, Test acc: 77.40%\n",
      "Epoch: 1410 | Loss: 0.48865, Accuracy: 76.95% | Test loss: 0.48712, Test acc: 77.40%\n",
      "Epoch: 1420 | Loss: 0.48864, Accuracy: 76.95% | Test loss: 0.48711, Test acc: 77.40%\n",
      "Epoch: 1430 | Loss: 0.48864, Accuracy: 76.95% | Test loss: 0.48711, Test acc: 77.40%\n",
      "Epoch: 1440 | Loss: 0.48863, Accuracy: 76.95% | Test loss: 0.48710, Test acc: 77.40%\n",
      "Epoch: 1450 | Loss: 0.48863, Accuracy: 76.95% | Test loss: 0.48710, Test acc: 77.40%\n",
      "Epoch: 1460 | Loss: 0.48862, Accuracy: 76.95% | Test loss: 0.48709, Test acc: 77.40%\n",
      "Epoch: 1470 | Loss: 0.48861, Accuracy: 76.95% | Test loss: 0.48709, Test acc: 77.40%\n",
      "Epoch: 1480 | Loss: 0.48861, Accuracy: 76.95% | Test loss: 0.48708, Test acc: 77.40%\n",
      "Epoch: 1490 | Loss: 0.48860, Accuracy: 76.95% | Test loss: 0.48708, Test acc: 77.40%\n",
      "Epoch: 1500 | Loss: 0.48860, Accuracy: 76.95% | Test loss: 0.48707, Test acc: 77.40%\n",
      "Epoch: 1510 | Loss: 0.48859, Accuracy: 76.94% | Test loss: 0.48707, Test acc: 77.40%\n",
      "Epoch: 1520 | Loss: 0.48858, Accuracy: 76.94% | Test loss: 0.48706, Test acc: 77.42%\n",
      "Epoch: 1530 | Loss: 0.48858, Accuracy: 76.94% | Test loss: 0.48706, Test acc: 77.42%\n",
      "Epoch: 1540 | Loss: 0.48857, Accuracy: 76.94% | Test loss: 0.48705, Test acc: 77.42%\n",
      "Epoch: 1550 | Loss: 0.48857, Accuracy: 76.94% | Test loss: 0.48705, Test acc: 77.42%\n",
      "Epoch: 1560 | Loss: 0.48856, Accuracy: 76.94% | Test loss: 0.48704, Test acc: 77.42%\n",
      "Epoch: 1570 | Loss: 0.48855, Accuracy: 76.94% | Test loss: 0.48704, Test acc: 77.42%\n",
      "Epoch: 1580 | Loss: 0.48855, Accuracy: 76.94% | Test loss: 0.48703, Test acc: 77.42%\n",
      "Epoch: 1590 | Loss: 0.48854, Accuracy: 76.94% | Test loss: 0.48703, Test acc: 77.42%\n",
      "Epoch: 1600 | Loss: 0.48854, Accuracy: 76.94% | Test loss: 0.48702, Test acc: 77.42%\n",
      "Epoch: 1610 | Loss: 0.48853, Accuracy: 76.94% | Test loss: 0.48702, Test acc: 77.42%\n",
      "Epoch: 1620 | Loss: 0.48853, Accuracy: 76.93% | Test loss: 0.48701, Test acc: 77.42%\n",
      "Epoch: 1630 | Loss: 0.48852, Accuracy: 76.93% | Test loss: 0.48701, Test acc: 77.42%\n",
      "Epoch: 1640 | Loss: 0.48851, Accuracy: 76.92% | Test loss: 0.48700, Test acc: 77.42%\n",
      "Epoch: 1650 | Loss: 0.48851, Accuracy: 76.92% | Test loss: 0.48700, Test acc: 77.42%\n",
      "Epoch: 1660 | Loss: 0.48850, Accuracy: 76.92% | Test loss: 0.48699, Test acc: 77.42%\n",
      "Epoch: 1670 | Loss: 0.48850, Accuracy: 76.92% | Test loss: 0.48699, Test acc: 77.42%\n",
      "Epoch: 1680 | Loss: 0.48849, Accuracy: 76.92% | Test loss: 0.48698, Test acc: 77.42%\n",
      "Epoch: 1690 | Loss: 0.48848, Accuracy: 76.92% | Test loss: 0.48698, Test acc: 77.42%\n",
      "Epoch: 1700 | Loss: 0.48848, Accuracy: 76.92% | Test loss: 0.48697, Test acc: 77.40%\n",
      "Epoch: 1710 | Loss: 0.48847, Accuracy: 76.91% | Test loss: 0.48697, Test acc: 77.40%\n",
      "Epoch: 1720 | Loss: 0.48847, Accuracy: 76.91% | Test loss: 0.48696, Test acc: 77.40%\n",
      "Epoch: 1730 | Loss: 0.48846, Accuracy: 76.91% | Test loss: 0.48696, Test acc: 77.40%\n",
      "Epoch: 1740 | Loss: 0.48845, Accuracy: 76.91% | Test loss: 0.48695, Test acc: 77.40%\n",
      "Epoch: 1750 | Loss: 0.48845, Accuracy: 76.91% | Test loss: 0.48695, Test acc: 77.40%\n",
      "Epoch: 1760 | Loss: 0.48844, Accuracy: 76.91% | Test loss: 0.48694, Test acc: 77.40%\n",
      "Epoch: 1770 | Loss: 0.48844, Accuracy: 76.91% | Test loss: 0.48694, Test acc: 77.40%\n",
      "Epoch: 1780 | Loss: 0.48843, Accuracy: 76.91% | Test loss: 0.48693, Test acc: 77.40%\n",
      "Epoch: 1790 | Loss: 0.48843, Accuracy: 76.90% | Test loss: 0.48693, Test acc: 77.40%\n",
      "Epoch: 1800 | Loss: 0.48842, Accuracy: 76.90% | Test loss: 0.48693, Test acc: 77.40%\n",
      "Epoch: 1810 | Loss: 0.48841, Accuracy: 76.90% | Test loss: 0.48692, Test acc: 77.40%\n",
      "Epoch: 1820 | Loss: 0.48841, Accuracy: 76.90% | Test loss: 0.48692, Test acc: 77.40%\n",
      "Epoch: 1830 | Loss: 0.48840, Accuracy: 76.89% | Test loss: 0.48691, Test acc: 77.40%\n",
      "Epoch: 1840 | Loss: 0.48840, Accuracy: 76.89% | Test loss: 0.48691, Test acc: 77.40%\n",
      "Epoch: 1850 | Loss: 0.48839, Accuracy: 76.89% | Test loss: 0.48690, Test acc: 77.40%\n",
      "Epoch: 1860 | Loss: 0.48839, Accuracy: 76.89% | Test loss: 0.48690, Test acc: 77.40%\n",
      "Epoch: 1870 | Loss: 0.48838, Accuracy: 76.89% | Test loss: 0.48689, Test acc: 77.40%\n",
      "Epoch: 1880 | Loss: 0.48837, Accuracy: 76.89% | Test loss: 0.48689, Test acc: 77.38%\n",
      "Epoch: 1890 | Loss: 0.48837, Accuracy: 76.89% | Test loss: 0.48688, Test acc: 77.38%\n",
      "Epoch: 1900 | Loss: 0.48836, Accuracy: 76.89% | Test loss: 0.48688, Test acc: 77.38%\n",
      "Epoch: 1910 | Loss: 0.48836, Accuracy: 76.89% | Test loss: 0.48687, Test acc: 77.38%\n",
      "Epoch: 1920 | Loss: 0.48835, Accuracy: 76.89% | Test loss: 0.48687, Test acc: 77.38%\n",
      "Epoch: 1930 | Loss: 0.48835, Accuracy: 76.89% | Test loss: 0.48686, Test acc: 77.35%\n",
      "Epoch: 1940 | Loss: 0.48834, Accuracy: 76.89% | Test loss: 0.48686, Test acc: 77.35%\n",
      "Epoch: 1950 | Loss: 0.48833, Accuracy: 76.89% | Test loss: 0.48685, Test acc: 77.35%\n",
      "Epoch: 1960 | Loss: 0.48833, Accuracy: 76.89% | Test loss: 0.48685, Test acc: 77.35%\n",
      "Epoch: 1970 | Loss: 0.48832, Accuracy: 76.90% | Test loss: 0.48684, Test acc: 77.35%\n",
      "Epoch: 1980 | Loss: 0.48832, Accuracy: 76.90% | Test loss: 0.48684, Test acc: 77.35%\n",
      "Epoch: 1990 | Loss: 0.48831, Accuracy: 76.90% | Test loss: 0.48683, Test acc: 77.35%\n",
      "Epoch: 2000 | Loss: 0.48831, Accuracy: 76.90% | Test loss: 0.48683, Test acc: 77.35%\n",
      "Epoch: 2010 | Loss: 0.48830, Accuracy: 76.90% | Test loss: 0.48682, Test acc: 77.35%\n",
      "Epoch: 2020 | Loss: 0.48829, Accuracy: 76.90% | Test loss: 0.48682, Test acc: 77.35%\n",
      "Epoch: 2030 | Loss: 0.48829, Accuracy: 76.90% | Test loss: 0.48681, Test acc: 77.35%\n",
      "Epoch: 2040 | Loss: 0.48828, Accuracy: 76.90% | Test loss: 0.48681, Test acc: 77.38%\n",
      "Epoch: 2050 | Loss: 0.48828, Accuracy: 76.90% | Test loss: 0.48680, Test acc: 77.38%\n",
      "Epoch: 2060 | Loss: 0.48827, Accuracy: 76.90% | Test loss: 0.48680, Test acc: 77.38%\n",
      "Epoch: 2070 | Loss: 0.48826, Accuracy: 76.93% | Test loss: 0.48679, Test acc: 77.42%\n",
      "Epoch: 2080 | Loss: 0.48826, Accuracy: 76.93% | Test loss: 0.48679, Test acc: 77.42%\n",
      "Epoch: 2090 | Loss: 0.48825, Accuracy: 76.93% | Test loss: 0.48678, Test acc: 77.42%\n",
      "Epoch: 2100 | Loss: 0.48825, Accuracy: 76.93% | Test loss: 0.48678, Test acc: 77.42%\n",
      "Epoch: 2110 | Loss: 0.48824, Accuracy: 76.93% | Test loss: 0.48677, Test acc: 77.42%\n",
      "Epoch: 2120 | Loss: 0.48824, Accuracy: 76.94% | Test loss: 0.48677, Test acc: 77.42%\n",
      "Epoch: 2130 | Loss: 0.48823, Accuracy: 76.94% | Test loss: 0.48677, Test acc: 77.42%\n",
      "Epoch: 2140 | Loss: 0.48823, Accuracy: 76.94% | Test loss: 0.48676, Test acc: 77.42%\n",
      "Epoch: 2150 | Loss: 0.48822, Accuracy: 76.94% | Test loss: 0.48676, Test acc: 77.42%\n",
      "Epoch: 2160 | Loss: 0.48821, Accuracy: 76.94% | Test loss: 0.48675, Test acc: 77.42%\n",
      "Epoch: 2170 | Loss: 0.48821, Accuracy: 76.94% | Test loss: 0.48675, Test acc: 77.42%\n",
      "Epoch: 2180 | Loss: 0.48820, Accuracy: 76.94% | Test loss: 0.48674, Test acc: 77.42%\n",
      "Epoch: 2190 | Loss: 0.48820, Accuracy: 76.94% | Test loss: 0.48674, Test acc: 77.42%\n",
      "Epoch: 2200 | Loss: 0.48819, Accuracy: 76.94% | Test loss: 0.48673, Test acc: 77.42%\n",
      "Epoch: 2210 | Loss: 0.48818, Accuracy: 76.94% | Test loss: 0.48673, Test acc: 77.42%\n",
      "Epoch: 2220 | Loss: 0.48818, Accuracy: 76.94% | Test loss: 0.48672, Test acc: 77.42%\n",
      "Epoch: 2230 | Loss: 0.48817, Accuracy: 76.94% | Test loss: 0.48672, Test acc: 77.42%\n",
      "Epoch: 2240 | Loss: 0.48817, Accuracy: 76.94% | Test loss: 0.48671, Test acc: 77.42%\n",
      "Epoch: 2250 | Loss: 0.48816, Accuracy: 76.94% | Test loss: 0.48671, Test acc: 77.42%\n",
      "Epoch: 2260 | Loss: 0.48816, Accuracy: 76.94% | Test loss: 0.48670, Test acc: 77.42%\n",
      "Epoch: 2270 | Loss: 0.48815, Accuracy: 76.94% | Test loss: 0.48670, Test acc: 77.42%\n",
      "Epoch: 2280 | Loss: 0.48815, Accuracy: 76.94% | Test loss: 0.48669, Test acc: 77.42%\n",
      "Epoch: 2290 | Loss: 0.48814, Accuracy: 76.94% | Test loss: 0.48669, Test acc: 77.42%\n",
      "Epoch: 2300 | Loss: 0.48813, Accuracy: 76.94% | Test loss: 0.48668, Test acc: 77.42%\n",
      "Epoch: 2310 | Loss: 0.48813, Accuracy: 76.94% | Test loss: 0.48668, Test acc: 77.42%\n",
      "Epoch: 2320 | Loss: 0.48812, Accuracy: 76.94% | Test loss: 0.48667, Test acc: 77.45%\n",
      "Epoch: 2330 | Loss: 0.48812, Accuracy: 76.94% | Test loss: 0.48667, Test acc: 77.45%\n",
      "Epoch: 2340 | Loss: 0.48811, Accuracy: 76.94% | Test loss: 0.48666, Test acc: 77.45%\n",
      "Epoch: 2350 | Loss: 0.48811, Accuracy: 76.94% | Test loss: 0.48666, Test acc: 77.45%\n",
      "Epoch: 2360 | Loss: 0.48810, Accuracy: 76.94% | Test loss: 0.48666, Test acc: 77.45%\n",
      "Epoch: 2370 | Loss: 0.48809, Accuracy: 76.94% | Test loss: 0.48665, Test acc: 77.45%\n",
      "Epoch: 2380 | Loss: 0.48809, Accuracy: 76.94% | Test loss: 0.48665, Test acc: 77.45%\n",
      "Epoch: 2390 | Loss: 0.48808, Accuracy: 76.91% | Test loss: 0.48664, Test acc: 77.40%\n",
      "Epoch: 2400 | Loss: 0.48808, Accuracy: 76.91% | Test loss: 0.48664, Test acc: 77.40%\n",
      "Epoch: 2410 | Loss: 0.48807, Accuracy: 76.91% | Test loss: 0.48663, Test acc: 77.40%\n",
      "Epoch: 2420 | Loss: 0.48807, Accuracy: 76.91% | Test loss: 0.48663, Test acc: 77.40%\n",
      "Epoch: 2430 | Loss: 0.48806, Accuracy: 76.91% | Test loss: 0.48662, Test acc: 77.40%\n",
      "Epoch: 2440 | Loss: 0.48805, Accuracy: 76.91% | Test loss: 0.48662, Test acc: 77.40%\n",
      "Epoch: 2450 | Loss: 0.48805, Accuracy: 76.91% | Test loss: 0.48661, Test acc: 77.40%\n",
      "Epoch: 2460 | Loss: 0.48804, Accuracy: 76.91% | Test loss: 0.48661, Test acc: 77.40%\n",
      "Epoch: 2470 | Loss: 0.48804, Accuracy: 76.91% | Test loss: 0.48660, Test acc: 77.40%\n",
      "Epoch: 2480 | Loss: 0.48803, Accuracy: 76.91% | Test loss: 0.48660, Test acc: 77.40%\n",
      "Epoch: 2490 | Loss: 0.48803, Accuracy: 76.91% | Test loss: 0.48659, Test acc: 77.40%\n",
      "Epoch: 2500 | Loss: 0.48802, Accuracy: 76.91% | Test loss: 0.48659, Test acc: 77.40%\n",
      "Epoch: 2510 | Loss: 0.48802, Accuracy: 76.91% | Test loss: 0.48658, Test acc: 77.40%\n",
      "Epoch: 2520 | Loss: 0.48801, Accuracy: 76.91% | Test loss: 0.48658, Test acc: 77.40%\n",
      "Epoch: 2530 | Loss: 0.48800, Accuracy: 76.91% | Test loss: 0.48657, Test acc: 77.40%\n",
      "Epoch: 2540 | Loss: 0.48800, Accuracy: 76.91% | Test loss: 0.48657, Test acc: 77.40%\n",
      "Epoch: 2550 | Loss: 0.48799, Accuracy: 76.91% | Test loss: 0.48656, Test acc: 77.40%\n",
      "Epoch: 2560 | Loss: 0.48799, Accuracy: 76.91% | Test loss: 0.48656, Test acc: 77.40%\n",
      "Epoch: 2570 | Loss: 0.48798, Accuracy: 76.91% | Test loss: 0.48656, Test acc: 77.40%\n",
      "Epoch: 2580 | Loss: 0.48798, Accuracy: 76.91% | Test loss: 0.48655, Test acc: 77.40%\n",
      "Epoch: 2590 | Loss: 0.48797, Accuracy: 76.91% | Test loss: 0.48655, Test acc: 77.40%\n",
      "Epoch: 2600 | Loss: 0.48796, Accuracy: 76.91% | Test loss: 0.48654, Test acc: 77.40%\n",
      "Epoch: 2610 | Loss: 0.48796, Accuracy: 76.91% | Test loss: 0.48654, Test acc: 77.40%\n",
      "Epoch: 2620 | Loss: 0.48795, Accuracy: 76.91% | Test loss: 0.48653, Test acc: 77.40%\n",
      "Epoch: 2630 | Loss: 0.48795, Accuracy: 76.91% | Test loss: 0.48653, Test acc: 77.40%\n",
      "Epoch: 2640 | Loss: 0.48794, Accuracy: 76.91% | Test loss: 0.48652, Test acc: 77.40%\n",
      "Epoch: 2650 | Loss: 0.48794, Accuracy: 76.91% | Test loss: 0.48652, Test acc: 77.40%\n",
      "Epoch: 2660 | Loss: 0.48793, Accuracy: 76.91% | Test loss: 0.48651, Test acc: 77.40%\n",
      "Epoch: 2670 | Loss: 0.48793, Accuracy: 76.92% | Test loss: 0.48651, Test acc: 77.40%\n",
      "Epoch: 2680 | Loss: 0.48792, Accuracy: 76.92% | Test loss: 0.48650, Test acc: 77.40%\n",
      "Epoch: 2690 | Loss: 0.48791, Accuracy: 76.92% | Test loss: 0.48650, Test acc: 77.40%\n",
      "Epoch: 2700 | Loss: 0.48791, Accuracy: 76.92% | Test loss: 0.48649, Test acc: 77.40%\n",
      "Epoch: 2710 | Loss: 0.48790, Accuracy: 76.92% | Test loss: 0.48649, Test acc: 77.40%\n",
      "Epoch: 2720 | Loss: 0.48790, Accuracy: 76.92% | Test loss: 0.48648, Test acc: 77.40%\n",
      "Epoch: 2730 | Loss: 0.48789, Accuracy: 76.92% | Test loss: 0.48648, Test acc: 77.40%\n",
      "Epoch: 2740 | Loss: 0.48789, Accuracy: 76.92% | Test loss: 0.48647, Test acc: 77.40%\n",
      "Epoch: 2750 | Loss: 0.48788, Accuracy: 76.93% | Test loss: 0.48647, Test acc: 77.40%\n",
      "Epoch: 2760 | Loss: 0.48788, Accuracy: 76.93% | Test loss: 0.48647, Test acc: 77.40%\n",
      "Epoch: 2770 | Loss: 0.48787, Accuracy: 76.93% | Test loss: 0.48646, Test acc: 77.40%\n",
      "Epoch: 2780 | Loss: 0.48786, Accuracy: 76.93% | Test loss: 0.48646, Test acc: 77.40%\n",
      "Epoch: 2790 | Loss: 0.48786, Accuracy: 76.93% | Test loss: 0.48645, Test acc: 77.40%\n",
      "Epoch: 2800 | Loss: 0.48785, Accuracy: 76.93% | Test loss: 0.48645, Test acc: 77.40%\n",
      "Epoch: 2810 | Loss: 0.48785, Accuracy: 76.93% | Test loss: 0.48644, Test acc: 77.40%\n",
      "Epoch: 2820 | Loss: 0.48784, Accuracy: 76.94% | Test loss: 0.48644, Test acc: 77.40%\n",
      "Epoch: 2830 | Loss: 0.48784, Accuracy: 76.94% | Test loss: 0.48643, Test acc: 77.40%\n",
      "Epoch: 2840 | Loss: 0.48783, Accuracy: 76.94% | Test loss: 0.48643, Test acc: 77.40%\n",
      "Epoch: 2850 | Loss: 0.48783, Accuracy: 76.94% | Test loss: 0.48642, Test acc: 77.42%\n",
      "Epoch: 2860 | Loss: 0.48782, Accuracy: 76.94% | Test loss: 0.48642, Test acc: 77.42%\n",
      "Epoch: 2870 | Loss: 0.48782, Accuracy: 76.94% | Test loss: 0.48641, Test acc: 77.42%\n",
      "Epoch: 2880 | Loss: 0.48781, Accuracy: 76.94% | Test loss: 0.48641, Test acc: 77.42%\n",
      "Epoch: 2890 | Loss: 0.48780, Accuracy: 76.94% | Test loss: 0.48640, Test acc: 77.42%\n",
      "Epoch: 2900 | Loss: 0.48780, Accuracy: 76.94% | Test loss: 0.48640, Test acc: 77.42%\n",
      "Epoch: 2910 | Loss: 0.48779, Accuracy: 76.94% | Test loss: 0.48640, Test acc: 77.42%\n",
      "Epoch: 2920 | Loss: 0.48779, Accuracy: 76.94% | Test loss: 0.48639, Test acc: 77.42%\n",
      "Epoch: 2930 | Loss: 0.48778, Accuracy: 76.94% | Test loss: 0.48639, Test acc: 77.42%\n",
      "Epoch: 2940 | Loss: 0.48778, Accuracy: 76.94% | Test loss: 0.48638, Test acc: 77.42%\n",
      "Epoch: 2950 | Loss: 0.48777, Accuracy: 76.94% | Test loss: 0.48638, Test acc: 77.42%\n",
      "Epoch: 2960 | Loss: 0.48777, Accuracy: 76.94% | Test loss: 0.48637, Test acc: 77.42%\n",
      "Epoch: 2970 | Loss: 0.48776, Accuracy: 76.94% | Test loss: 0.48637, Test acc: 77.42%\n",
      "Epoch: 2980 | Loss: 0.48775, Accuracy: 76.94% | Test loss: 0.48636, Test acc: 77.42%\n",
      "Epoch: 2990 | Loss: 0.48775, Accuracy: 76.94% | Test loss: 0.48636, Test acc: 77.42%\n",
      "Epoch: 3000 | Loss: 0.48774, Accuracy: 76.94% | Test loss: 0.48635, Test acc: 77.42%\n",
      "Epoch: 3010 | Loss: 0.48774, Accuracy: 76.94% | Test loss: 0.48635, Test acc: 77.42%\n",
      "Epoch: 3020 | Loss: 0.48773, Accuracy: 76.94% | Test loss: 0.48634, Test acc: 77.42%\n",
      "Epoch: 3030 | Loss: 0.48773, Accuracy: 76.94% | Test loss: 0.48634, Test acc: 77.42%\n",
      "Epoch: 3040 | Loss: 0.48772, Accuracy: 76.94% | Test loss: 0.48634, Test acc: 77.42%\n",
      "Epoch: 3050 | Loss: 0.48772, Accuracy: 76.94% | Test loss: 0.48633, Test acc: 77.42%\n",
      "Epoch: 3060 | Loss: 0.48771, Accuracy: 76.94% | Test loss: 0.48633, Test acc: 77.42%\n",
      "Epoch: 3070 | Loss: 0.48770, Accuracy: 76.94% | Test loss: 0.48632, Test acc: 77.42%\n",
      "Epoch: 3080 | Loss: 0.48770, Accuracy: 76.94% | Test loss: 0.48632, Test acc: 77.42%\n",
      "Epoch: 3090 | Loss: 0.48769, Accuracy: 76.94% | Test loss: 0.48631, Test acc: 77.42%\n",
      "Epoch: 3100 | Loss: 0.48769, Accuracy: 76.94% | Test loss: 0.48631, Test acc: 77.42%\n",
      "Epoch: 3110 | Loss: 0.48768, Accuracy: 76.94% | Test loss: 0.48630, Test acc: 77.42%\n",
      "Epoch: 3120 | Loss: 0.48768, Accuracy: 76.94% | Test loss: 0.48630, Test acc: 77.42%\n",
      "Epoch: 3130 | Loss: 0.48767, Accuracy: 76.94% | Test loss: 0.48629, Test acc: 77.42%\n",
      "Epoch: 3140 | Loss: 0.48767, Accuracy: 76.94% | Test loss: 0.48629, Test acc: 77.40%\n",
      "Epoch: 3150 | Loss: 0.48766, Accuracy: 76.94% | Test loss: 0.48628, Test acc: 77.40%\n",
      "Epoch: 3160 | Loss: 0.48766, Accuracy: 76.94% | Test loss: 0.48628, Test acc: 77.40%\n",
      "Epoch: 3170 | Loss: 0.48765, Accuracy: 76.94% | Test loss: 0.48628, Test acc: 77.40%\n",
      "Epoch: 3180 | Loss: 0.48764, Accuracy: 76.94% | Test loss: 0.48627, Test acc: 77.40%\n",
      "Epoch: 3190 | Loss: 0.48764, Accuracy: 76.94% | Test loss: 0.48627, Test acc: 77.40%\n",
      "Epoch: 3200 | Loss: 0.48763, Accuracy: 76.94% | Test loss: 0.48626, Test acc: 77.40%\n",
      "Epoch: 3210 | Loss: 0.48763, Accuracy: 76.94% | Test loss: 0.48626, Test acc: 77.40%\n",
      "Epoch: 3220 | Loss: 0.48762, Accuracy: 76.94% | Test loss: 0.48625, Test acc: 77.40%\n",
      "Epoch: 3230 | Loss: 0.48762, Accuracy: 76.94% | Test loss: 0.48625, Test acc: 77.40%\n",
      "Epoch: 3240 | Loss: 0.48761, Accuracy: 76.94% | Test loss: 0.48624, Test acc: 77.40%\n",
      "Epoch: 3250 | Loss: 0.48761, Accuracy: 76.94% | Test loss: 0.48624, Test acc: 77.40%\n",
      "Epoch: 3260 | Loss: 0.48760, Accuracy: 76.94% | Test loss: 0.48623, Test acc: 77.40%\n",
      "Epoch: 3270 | Loss: 0.48760, Accuracy: 76.94% | Test loss: 0.48623, Test acc: 77.40%\n",
      "Epoch: 3280 | Loss: 0.48759, Accuracy: 76.94% | Test loss: 0.48622, Test acc: 77.40%\n",
      "Epoch: 3290 | Loss: 0.48759, Accuracy: 76.94% | Test loss: 0.48622, Test acc: 77.40%\n",
      "Epoch: 3300 | Loss: 0.48758, Accuracy: 76.94% | Test loss: 0.48622, Test acc: 77.40%\n",
      "Epoch: 3310 | Loss: 0.48757, Accuracy: 76.94% | Test loss: 0.48621, Test acc: 77.40%\n",
      "Epoch: 3320 | Loss: 0.48757, Accuracy: 76.94% | Test loss: 0.48621, Test acc: 77.40%\n",
      "Epoch: 3330 | Loss: 0.48756, Accuracy: 76.94% | Test loss: 0.48620, Test acc: 77.40%\n",
      "Epoch: 3340 | Loss: 0.48756, Accuracy: 76.94% | Test loss: 0.48620, Test acc: 77.40%\n",
      "Epoch: 3350 | Loss: 0.48755, Accuracy: 76.95% | Test loss: 0.48619, Test acc: 77.40%\n",
      "Epoch: 3360 | Loss: 0.48755, Accuracy: 76.95% | Test loss: 0.48619, Test acc: 77.40%\n",
      "Epoch: 3370 | Loss: 0.48754, Accuracy: 76.95% | Test loss: 0.48618, Test acc: 77.40%\n",
      "Epoch: 3380 | Loss: 0.48754, Accuracy: 76.94% | Test loss: 0.48618, Test acc: 77.40%\n",
      "Epoch: 3390 | Loss: 0.48753, Accuracy: 76.94% | Test loss: 0.48617, Test acc: 77.40%\n",
      "Epoch: 3400 | Loss: 0.48753, Accuracy: 76.94% | Test loss: 0.48617, Test acc: 77.40%\n",
      "Epoch: 3410 | Loss: 0.48752, Accuracy: 76.94% | Test loss: 0.48617, Test acc: 77.40%\n",
      "Epoch: 3420 | Loss: 0.48751, Accuracy: 76.94% | Test loss: 0.48616, Test acc: 77.40%\n",
      "Epoch: 3430 | Loss: 0.48751, Accuracy: 76.94% | Test loss: 0.48616, Test acc: 77.40%\n",
      "Epoch: 3440 | Loss: 0.48750, Accuracy: 76.94% | Test loss: 0.48615, Test acc: 77.40%\n",
      "Epoch: 3450 | Loss: 0.48750, Accuracy: 76.94% | Test loss: 0.48615, Test acc: 77.40%\n",
      "Epoch: 3460 | Loss: 0.48749, Accuracy: 76.94% | Test loss: 0.48614, Test acc: 77.40%\n",
      "Epoch: 3470 | Loss: 0.48749, Accuracy: 76.94% | Test loss: 0.48614, Test acc: 77.40%\n",
      "Epoch: 3480 | Loss: 0.48748, Accuracy: 76.94% | Test loss: 0.48613, Test acc: 77.40%\n",
      "Epoch: 3490 | Loss: 0.48748, Accuracy: 76.94% | Test loss: 0.48613, Test acc: 77.40%\n",
      "Epoch: 3500 | Loss: 0.48747, Accuracy: 76.94% | Test loss: 0.48612, Test acc: 77.40%\n",
      "Epoch: 3510 | Loss: 0.48747, Accuracy: 76.95% | Test loss: 0.48612, Test acc: 77.40%\n",
      "Epoch: 3520 | Loss: 0.48746, Accuracy: 76.95% | Test loss: 0.48612, Test acc: 77.40%\n",
      "Epoch: 3530 | Loss: 0.48746, Accuracy: 76.94% | Test loss: 0.48611, Test acc: 77.40%\n",
      "Epoch: 3540 | Loss: 0.48745, Accuracy: 76.94% | Test loss: 0.48611, Test acc: 77.40%\n",
      "Epoch: 3550 | Loss: 0.48744, Accuracy: 76.94% | Test loss: 0.48610, Test acc: 77.40%\n",
      "Epoch: 3560 | Loss: 0.48744, Accuracy: 76.95% | Test loss: 0.48610, Test acc: 77.40%\n",
      "Epoch: 3570 | Loss: 0.48743, Accuracy: 76.96% | Test loss: 0.48609, Test acc: 77.40%\n",
      "Epoch: 3580 | Loss: 0.48743, Accuracy: 76.96% | Test loss: 0.48609, Test acc: 77.40%\n",
      "Epoch: 3590 | Loss: 0.48742, Accuracy: 76.96% | Test loss: 0.48608, Test acc: 77.40%\n",
      "Epoch: 3600 | Loss: 0.48742, Accuracy: 76.96% | Test loss: 0.48608, Test acc: 77.40%\n",
      "Epoch: 3610 | Loss: 0.48741, Accuracy: 76.96% | Test loss: 0.48607, Test acc: 77.40%\n",
      "Epoch: 3620 | Loss: 0.48741, Accuracy: 76.96% | Test loss: 0.48607, Test acc: 77.40%\n",
      "Epoch: 3630 | Loss: 0.48740, Accuracy: 76.96% | Test loss: 0.48607, Test acc: 77.40%\n",
      "Epoch: 3640 | Loss: 0.48740, Accuracy: 76.96% | Test loss: 0.48606, Test acc: 77.40%\n",
      "Epoch: 3650 | Loss: 0.48739, Accuracy: 76.96% | Test loss: 0.48606, Test acc: 77.40%\n",
      "Epoch: 3660 | Loss: 0.48739, Accuracy: 76.96% | Test loss: 0.48605, Test acc: 77.40%\n",
      "Epoch: 3670 | Loss: 0.48738, Accuracy: 76.97% | Test loss: 0.48605, Test acc: 77.40%\n",
      "Epoch: 3680 | Loss: 0.48738, Accuracy: 76.97% | Test loss: 0.48604, Test acc: 77.40%\n",
      "Epoch: 3690 | Loss: 0.48737, Accuracy: 76.97% | Test loss: 0.48604, Test acc: 77.40%\n",
      "Epoch: 3700 | Loss: 0.48736, Accuracy: 76.97% | Test loss: 0.48603, Test acc: 77.40%\n",
      "Epoch: 3710 | Loss: 0.48736, Accuracy: 76.98% | Test loss: 0.48603, Test acc: 77.40%\n",
      "Epoch: 3720 | Loss: 0.48735, Accuracy: 76.98% | Test loss: 0.48602, Test acc: 77.40%\n",
      "Epoch: 3730 | Loss: 0.48735, Accuracy: 76.98% | Test loss: 0.48602, Test acc: 77.40%\n",
      "Epoch: 3740 | Loss: 0.48734, Accuracy: 76.98% | Test loss: 0.48602, Test acc: 77.40%\n",
      "Epoch: 3750 | Loss: 0.48734, Accuracy: 76.98% | Test loss: 0.48601, Test acc: 77.40%\n",
      "Epoch: 3760 | Loss: 0.48733, Accuracy: 76.99% | Test loss: 0.48601, Test acc: 77.48%\n",
      "Epoch: 3770 | Loss: 0.48733, Accuracy: 76.99% | Test loss: 0.48600, Test acc: 77.48%\n",
      "Epoch: 3780 | Loss: 0.48732, Accuracy: 77.00% | Test loss: 0.48600, Test acc: 77.48%\n",
      "Epoch: 3790 | Loss: 0.48732, Accuracy: 77.00% | Test loss: 0.48599, Test acc: 77.48%\n",
      "Epoch: 3800 | Loss: 0.48731, Accuracy: 77.00% | Test loss: 0.48599, Test acc: 77.48%\n",
      "Epoch: 3810 | Loss: 0.48731, Accuracy: 77.00% | Test loss: 0.48598, Test acc: 77.48%\n",
      "Epoch: 3820 | Loss: 0.48730, Accuracy: 77.01% | Test loss: 0.48598, Test acc: 77.48%\n",
      "Epoch: 3830 | Loss: 0.48730, Accuracy: 77.01% | Test loss: 0.48598, Test acc: 77.48%\n",
      "Epoch: 3840 | Loss: 0.48729, Accuracy: 77.01% | Test loss: 0.48597, Test acc: 77.48%\n",
      "Epoch: 3850 | Loss: 0.48729, Accuracy: 77.01% | Test loss: 0.48597, Test acc: 77.48%\n",
      "Epoch: 3860 | Loss: 0.48728, Accuracy: 77.01% | Test loss: 0.48596, Test acc: 77.48%\n",
      "Epoch: 3870 | Loss: 0.48727, Accuracy: 77.01% | Test loss: 0.48596, Test acc: 77.48%\n",
      "Epoch: 3880 | Loss: 0.48727, Accuracy: 77.01% | Test loss: 0.48595, Test acc: 77.48%\n",
      "Epoch: 3890 | Loss: 0.48726, Accuracy: 77.01% | Test loss: 0.48595, Test acc: 77.48%\n",
      "Epoch: 3900 | Loss: 0.48726, Accuracy: 77.01% | Test loss: 0.48594, Test acc: 77.48%\n",
      "Epoch: 3910 | Loss: 0.48725, Accuracy: 77.01% | Test loss: 0.48594, Test acc: 77.48%\n",
      "Epoch: 3920 | Loss: 0.48725, Accuracy: 77.01% | Test loss: 0.48594, Test acc: 77.48%\n",
      "Epoch: 3930 | Loss: 0.48724, Accuracy: 77.01% | Test loss: 0.48593, Test acc: 77.48%\n",
      "Epoch: 3940 | Loss: 0.48724, Accuracy: 77.01% | Test loss: 0.48593, Test acc: 77.48%\n",
      "Epoch: 3950 | Loss: 0.48723, Accuracy: 77.02% | Test loss: 0.48592, Test acc: 77.48%\n",
      "Epoch: 3960 | Loss: 0.48723, Accuracy: 77.02% | Test loss: 0.48592, Test acc: 77.48%\n",
      "Epoch: 3970 | Loss: 0.48722, Accuracy: 77.02% | Test loss: 0.48591, Test acc: 77.48%\n",
      "Epoch: 3980 | Loss: 0.48722, Accuracy: 77.02% | Test loss: 0.48591, Test acc: 77.48%\n",
      "Epoch: 3990 | Loss: 0.48721, Accuracy: 77.01% | Test loss: 0.48590, Test acc: 77.48%\n",
      "Epoch: 4000 | Loss: 0.48721, Accuracy: 77.01% | Test loss: 0.48590, Test acc: 77.48%\n",
      "Epoch: 4010 | Loss: 0.48720, Accuracy: 77.01% | Test loss: 0.48590, Test acc: 77.48%\n",
      "Epoch: 4020 | Loss: 0.48720, Accuracy: 77.01% | Test loss: 0.48589, Test acc: 77.48%\n",
      "Epoch: 4030 | Loss: 0.48719, Accuracy: 77.01% | Test loss: 0.48589, Test acc: 77.48%\n",
      "Epoch: 4040 | Loss: 0.48718, Accuracy: 77.01% | Test loss: 0.48588, Test acc: 77.48%\n",
      "Epoch: 4050 | Loss: 0.48718, Accuracy: 77.01% | Test loss: 0.48588, Test acc: 77.48%\n",
      "Epoch: 4060 | Loss: 0.48717, Accuracy: 77.01% | Test loss: 0.48587, Test acc: 77.48%\n",
      "Epoch: 4070 | Loss: 0.48717, Accuracy: 77.01% | Test loss: 0.48587, Test acc: 77.48%\n",
      "Epoch: 4080 | Loss: 0.48716, Accuracy: 77.01% | Test loss: 0.48586, Test acc: 77.48%\n",
      "Epoch: 4090 | Loss: 0.48716, Accuracy: 77.01% | Test loss: 0.48586, Test acc: 77.48%\n",
      "Epoch: 4100 | Loss: 0.48715, Accuracy: 77.01% | Test loss: 0.48586, Test acc: 77.48%\n",
      "Epoch: 4110 | Loss: 0.48715, Accuracy: 77.01% | Test loss: 0.48585, Test acc: 77.48%\n",
      "Epoch: 4120 | Loss: 0.48714, Accuracy: 77.01% | Test loss: 0.48585, Test acc: 77.48%\n",
      "Epoch: 4130 | Loss: 0.48714, Accuracy: 77.01% | Test loss: 0.48584, Test acc: 77.48%\n",
      "Epoch: 4140 | Loss: 0.48713, Accuracy: 77.01% | Test loss: 0.48584, Test acc: 77.48%\n",
      "Epoch: 4150 | Loss: 0.48713, Accuracy: 77.01% | Test loss: 0.48583, Test acc: 77.48%\n",
      "Epoch: 4160 | Loss: 0.48712, Accuracy: 77.01% | Test loss: 0.48583, Test acc: 77.48%\n",
      "Epoch: 4170 | Loss: 0.48712, Accuracy: 77.01% | Test loss: 0.48582, Test acc: 77.48%\n",
      "Epoch: 4180 | Loss: 0.48711, Accuracy: 77.01% | Test loss: 0.48582, Test acc: 77.48%\n",
      "Epoch: 4190 | Loss: 0.48711, Accuracy: 77.01% | Test loss: 0.48582, Test acc: 77.48%\n",
      "Epoch: 4200 | Loss: 0.48710, Accuracy: 77.01% | Test loss: 0.48581, Test acc: 77.48%\n",
      "Epoch: 4210 | Loss: 0.48710, Accuracy: 77.01% | Test loss: 0.48581, Test acc: 77.48%\n",
      "Epoch: 4220 | Loss: 0.48709, Accuracy: 77.01% | Test loss: 0.48580, Test acc: 77.48%\n",
      "Epoch: 4230 | Loss: 0.48709, Accuracy: 77.01% | Test loss: 0.48580, Test acc: 77.48%\n",
      "Epoch: 4240 | Loss: 0.48708, Accuracy: 77.01% | Test loss: 0.48579, Test acc: 77.48%\n",
      "Epoch: 4250 | Loss: 0.48707, Accuracy: 77.01% | Test loss: 0.48579, Test acc: 77.50%\n",
      "Epoch: 4260 | Loss: 0.48707, Accuracy: 77.01% | Test loss: 0.48578, Test acc: 77.50%\n",
      "Epoch: 4270 | Loss: 0.48706, Accuracy: 77.01% | Test loss: 0.48578, Test acc: 77.50%\n",
      "Epoch: 4280 | Loss: 0.48706, Accuracy: 77.01% | Test loss: 0.48578, Test acc: 77.50%\n",
      "Epoch: 4290 | Loss: 0.48705, Accuracy: 77.01% | Test loss: 0.48577, Test acc: 77.50%\n",
      "Epoch: 4300 | Loss: 0.48705, Accuracy: 77.01% | Test loss: 0.48577, Test acc: 77.50%\n",
      "Epoch: 4310 | Loss: 0.48704, Accuracy: 77.01% | Test loss: 0.48576, Test acc: 77.50%\n",
      "Epoch: 4320 | Loss: 0.48704, Accuracy: 77.01% | Test loss: 0.48576, Test acc: 77.50%\n",
      "Epoch: 4330 | Loss: 0.48703, Accuracy: 77.01% | Test loss: 0.48575, Test acc: 77.50%\n",
      "Epoch: 4340 | Loss: 0.48703, Accuracy: 77.01% | Test loss: 0.48575, Test acc: 77.50%\n",
      "Epoch: 4350 | Loss: 0.48702, Accuracy: 77.01% | Test loss: 0.48575, Test acc: 77.50%\n",
      "Epoch: 4360 | Loss: 0.48702, Accuracy: 77.01% | Test loss: 0.48574, Test acc: 77.50%\n",
      "Epoch: 4370 | Loss: 0.48701, Accuracy: 77.01% | Test loss: 0.48574, Test acc: 77.50%\n",
      "Epoch: 4380 | Loss: 0.48701, Accuracy: 77.01% | Test loss: 0.48573, Test acc: 77.50%\n",
      "Epoch: 4390 | Loss: 0.48700, Accuracy: 77.01% | Test loss: 0.48573, Test acc: 77.50%\n",
      "Epoch: 4400 | Loss: 0.48700, Accuracy: 77.01% | Test loss: 0.48572, Test acc: 77.50%\n",
      "Epoch: 4410 | Loss: 0.48699, Accuracy: 77.01% | Test loss: 0.48572, Test acc: 77.50%\n",
      "Epoch: 4420 | Loss: 0.48699, Accuracy: 77.02% | Test loss: 0.48571, Test acc: 77.50%\n",
      "Epoch: 4430 | Loss: 0.48698, Accuracy: 77.02% | Test loss: 0.48571, Test acc: 77.50%\n",
      "Epoch: 4440 | Loss: 0.48698, Accuracy: 77.02% | Test loss: 0.48571, Test acc: 77.50%\n",
      "Epoch: 4450 | Loss: 0.48697, Accuracy: 77.02% | Test loss: 0.48570, Test acc: 77.50%\n",
      "Epoch: 4460 | Loss: 0.48697, Accuracy: 77.02% | Test loss: 0.48570, Test acc: 77.53%\n",
      "Epoch: 4470 | Loss: 0.48696, Accuracy: 77.02% | Test loss: 0.48569, Test acc: 77.53%\n",
      "Epoch: 4480 | Loss: 0.48696, Accuracy: 77.02% | Test loss: 0.48569, Test acc: 77.53%\n",
      "Epoch: 4490 | Loss: 0.48695, Accuracy: 77.02% | Test loss: 0.48568, Test acc: 77.53%\n",
      "Epoch: 4500 | Loss: 0.48695, Accuracy: 77.02% | Test loss: 0.48568, Test acc: 77.53%\n",
      "Epoch: 4510 | Loss: 0.48694, Accuracy: 77.02% | Test loss: 0.48568, Test acc: 77.53%\n",
      "Epoch: 4520 | Loss: 0.48694, Accuracy: 77.02% | Test loss: 0.48567, Test acc: 77.53%\n",
      "Epoch: 4530 | Loss: 0.48693, Accuracy: 77.03% | Test loss: 0.48567, Test acc: 77.53%\n",
      "Epoch: 4540 | Loss: 0.48692, Accuracy: 77.03% | Test loss: 0.48566, Test acc: 77.53%\n",
      "Epoch: 4550 | Loss: 0.48692, Accuracy: 77.03% | Test loss: 0.48566, Test acc: 77.53%\n",
      "Epoch: 4560 | Loss: 0.48691, Accuracy: 77.02% | Test loss: 0.48565, Test acc: 77.53%\n",
      "Epoch: 4570 | Loss: 0.48691, Accuracy: 77.02% | Test loss: 0.48565, Test acc: 77.53%\n",
      "Epoch: 4580 | Loss: 0.48690, Accuracy: 77.02% | Test loss: 0.48564, Test acc: 77.53%\n",
      "Epoch: 4590 | Loss: 0.48690, Accuracy: 77.03% | Test loss: 0.48564, Test acc: 77.53%\n",
      "Epoch: 4600 | Loss: 0.48689, Accuracy: 77.03% | Test loss: 0.48564, Test acc: 77.53%\n",
      "Epoch: 4610 | Loss: 0.48689, Accuracy: 77.03% | Test loss: 0.48563, Test acc: 77.53%\n",
      "Epoch: 4620 | Loss: 0.48688, Accuracy: 77.03% | Test loss: 0.48563, Test acc: 77.53%\n",
      "Epoch: 4630 | Loss: 0.48688, Accuracy: 77.03% | Test loss: 0.48562, Test acc: 77.53%\n",
      "Epoch: 4640 | Loss: 0.48687, Accuracy: 77.03% | Test loss: 0.48562, Test acc: 77.53%\n",
      "Epoch: 4650 | Loss: 0.48687, Accuracy: 77.03% | Test loss: 0.48561, Test acc: 77.53%\n",
      "Epoch: 4660 | Loss: 0.48686, Accuracy: 77.03% | Test loss: 0.48561, Test acc: 77.53%\n",
      "Epoch: 4670 | Loss: 0.48686, Accuracy: 77.03% | Test loss: 0.48561, Test acc: 77.53%\n",
      "Epoch: 4680 | Loss: 0.48685, Accuracy: 77.03% | Test loss: 0.48560, Test acc: 77.53%\n",
      "Epoch: 4690 | Loss: 0.48685, Accuracy: 77.03% | Test loss: 0.48560, Test acc: 77.53%\n",
      "Epoch: 4700 | Loss: 0.48684, Accuracy: 77.03% | Test loss: 0.48559, Test acc: 77.53%\n",
      "Epoch: 4710 | Loss: 0.48684, Accuracy: 77.03% | Test loss: 0.48559, Test acc: 77.53%\n",
      "Epoch: 4720 | Loss: 0.48683, Accuracy: 77.03% | Test loss: 0.48558, Test acc: 77.53%\n",
      "Epoch: 4730 | Loss: 0.48683, Accuracy: 77.03% | Test loss: 0.48558, Test acc: 77.53%\n",
      "Epoch: 4740 | Loss: 0.48682, Accuracy: 77.03% | Test loss: 0.48558, Test acc: 77.53%\n",
      "Epoch: 4750 | Loss: 0.48682, Accuracy: 77.03% | Test loss: 0.48557, Test acc: 77.53%\n",
      "Epoch: 4760 | Loss: 0.48681, Accuracy: 77.03% | Test loss: 0.48557, Test acc: 77.53%\n",
      "Epoch: 4770 | Loss: 0.48681, Accuracy: 77.03% | Test loss: 0.48556, Test acc: 77.53%\n",
      "Epoch: 4780 | Loss: 0.48680, Accuracy: 77.03% | Test loss: 0.48556, Test acc: 77.53%\n",
      "Epoch: 4790 | Loss: 0.48680, Accuracy: 77.04% | Test loss: 0.48555, Test acc: 77.53%\n",
      "Epoch: 4800 | Loss: 0.48679, Accuracy: 77.04% | Test loss: 0.48555, Test acc: 77.53%\n",
      "Epoch: 4810 | Loss: 0.48679, Accuracy: 77.04% | Test loss: 0.48555, Test acc: 77.53%\n",
      "Epoch: 4820 | Loss: 0.48678, Accuracy: 77.04% | Test loss: 0.48554, Test acc: 77.53%\n",
      "Epoch: 4830 | Loss: 0.48678, Accuracy: 77.04% | Test loss: 0.48554, Test acc: 77.53%\n",
      "Epoch: 4840 | Loss: 0.48677, Accuracy: 77.04% | Test loss: 0.48553, Test acc: 77.53%\n",
      "Epoch: 4850 | Loss: 0.48677, Accuracy: 77.04% | Test loss: 0.48553, Test acc: 77.53%\n",
      "Epoch: 4860 | Loss: 0.48676, Accuracy: 77.04% | Test loss: 0.48552, Test acc: 77.53%\n",
      "Epoch: 4870 | Loss: 0.48676, Accuracy: 77.04% | Test loss: 0.48552, Test acc: 77.53%\n",
      "Epoch: 4880 | Loss: 0.48675, Accuracy: 77.04% | Test loss: 0.48552, Test acc: 77.53%\n",
      "Epoch: 4890 | Loss: 0.48675, Accuracy: 77.03% | Test loss: 0.48551, Test acc: 77.53%\n",
      "Epoch: 4900 | Loss: 0.48674, Accuracy: 77.03% | Test loss: 0.48551, Test acc: 77.53%\n",
      "Epoch: 4910 | Loss: 0.48674, Accuracy: 77.03% | Test loss: 0.48550, Test acc: 77.53%\n",
      "Epoch: 4920 | Loss: 0.48673, Accuracy: 77.03% | Test loss: 0.48550, Test acc: 77.53%\n",
      "Epoch: 4930 | Loss: 0.48673, Accuracy: 77.03% | Test loss: 0.48549, Test acc: 77.53%\n",
      "Epoch: 4940 | Loss: 0.48672, Accuracy: 77.03% | Test loss: 0.48549, Test acc: 77.53%\n",
      "Epoch: 4950 | Loss: 0.48672, Accuracy: 77.03% | Test loss: 0.48549, Test acc: 77.53%\n",
      "Epoch: 4960 | Loss: 0.48671, Accuracy: 77.03% | Test loss: 0.48548, Test acc: 77.53%\n",
      "Epoch: 4970 | Loss: 0.48671, Accuracy: 77.03% | Test loss: 0.48548, Test acc: 77.53%\n",
      "Epoch: 4980 | Loss: 0.48670, Accuracy: 77.03% | Test loss: 0.48547, Test acc: 77.53%\n",
      "Epoch: 4990 | Loss: 0.48670, Accuracy: 77.03% | Test loss: 0.48547, Test acc: 77.53%\n",
      "Epoch: 5000 | Loss: 0.48669, Accuracy: 77.03% | Test loss: 0.48546, Test acc: 77.53%\n",
      "Epoch: 5010 | Loss: 0.48669, Accuracy: 77.03% | Test loss: 0.48546, Test acc: 77.53%\n",
      "Epoch: 5020 | Loss: 0.48668, Accuracy: 77.03% | Test loss: 0.48546, Test acc: 77.53%\n",
      "Epoch: 5030 | Loss: 0.48668, Accuracy: 77.03% | Test loss: 0.48545, Test acc: 77.53%\n",
      "Epoch: 5040 | Loss: 0.48667, Accuracy: 77.03% | Test loss: 0.48545, Test acc: 77.53%\n",
      "Epoch: 5050 | Loss: 0.48667, Accuracy: 77.03% | Test loss: 0.48544, Test acc: 77.53%\n",
      "Epoch: 5060 | Loss: 0.48666, Accuracy: 77.03% | Test loss: 0.48544, Test acc: 77.53%\n",
      "Epoch: 5070 | Loss: 0.48666, Accuracy: 77.03% | Test loss: 0.48543, Test acc: 77.53%\n",
      "Epoch: 5080 | Loss: 0.48665, Accuracy: 77.03% | Test loss: 0.48543, Test acc: 77.53%\n",
      "Epoch: 5090 | Loss: 0.48664, Accuracy: 77.03% | Test loss: 0.48543, Test acc: 77.53%\n",
      "Epoch: 5100 | Loss: 0.48664, Accuracy: 77.03% | Test loss: 0.48542, Test acc: 77.53%\n",
      "Epoch: 5110 | Loss: 0.48664, Accuracy: 77.03% | Test loss: 0.48542, Test acc: 77.53%\n",
      "Epoch: 5120 | Loss: 0.48663, Accuracy: 77.03% | Test loss: 0.48541, Test acc: 77.53%\n",
      "Epoch: 5130 | Loss: 0.48662, Accuracy: 77.03% | Test loss: 0.48541, Test acc: 77.53%\n",
      "Epoch: 5140 | Loss: 0.48662, Accuracy: 77.03% | Test loss: 0.48540, Test acc: 77.53%\n",
      "Epoch: 5150 | Loss: 0.48661, Accuracy: 77.03% | Test loss: 0.48540, Test acc: 77.53%\n",
      "Epoch: 5160 | Loss: 0.48661, Accuracy: 77.03% | Test loss: 0.48539, Test acc: 77.53%\n",
      "Epoch: 5170 | Loss: 0.48660, Accuracy: 77.03% | Test loss: 0.48539, Test acc: 77.53%\n",
      "Epoch: 5180 | Loss: 0.48660, Accuracy: 77.03% | Test loss: 0.48539, Test acc: 77.53%\n",
      "Epoch: 5190 | Loss: 0.48659, Accuracy: 77.03% | Test loss: 0.48538, Test acc: 77.53%\n",
      "Epoch: 5200 | Loss: 0.48659, Accuracy: 77.04% | Test loss: 0.48538, Test acc: 77.53%\n",
      "Epoch: 5210 | Loss: 0.48658, Accuracy: 77.04% | Test loss: 0.48537, Test acc: 77.53%\n",
      "Epoch: 5220 | Loss: 0.48658, Accuracy: 77.04% | Test loss: 0.48537, Test acc: 77.53%\n",
      "Epoch: 5230 | Loss: 0.48657, Accuracy: 77.04% | Test loss: 0.48537, Test acc: 77.53%\n",
      "Epoch: 5240 | Loss: 0.48657, Accuracy: 77.04% | Test loss: 0.48536, Test acc: 77.53%\n",
      "Epoch: 5250 | Loss: 0.48656, Accuracy: 77.04% | Test loss: 0.48536, Test acc: 77.53%\n",
      "Epoch: 5260 | Loss: 0.48656, Accuracy: 77.04% | Test loss: 0.48535, Test acc: 77.53%\n",
      "Epoch: 5270 | Loss: 0.48655, Accuracy: 77.04% | Test loss: 0.48535, Test acc: 77.53%\n",
      "Epoch: 5280 | Loss: 0.48655, Accuracy: 77.04% | Test loss: 0.48534, Test acc: 77.53%\n",
      "Epoch: 5290 | Loss: 0.48654, Accuracy: 77.04% | Test loss: 0.48534, Test acc: 77.53%\n",
      "Epoch: 5300 | Loss: 0.48654, Accuracy: 77.04% | Test loss: 0.48534, Test acc: 77.53%\n",
      "Epoch: 5310 | Loss: 0.48653, Accuracy: 77.04% | Test loss: 0.48533, Test acc: 77.53%\n",
      "Epoch: 5320 | Loss: 0.48653, Accuracy: 77.04% | Test loss: 0.48533, Test acc: 77.53%\n",
      "Epoch: 5330 | Loss: 0.48652, Accuracy: 77.04% | Test loss: 0.48532, Test acc: 77.53%\n",
      "Epoch: 5340 | Loss: 0.48652, Accuracy: 77.04% | Test loss: 0.48532, Test acc: 77.53%\n",
      "Epoch: 5350 | Loss: 0.48651, Accuracy: 77.04% | Test loss: 0.48531, Test acc: 77.53%\n",
      "Epoch: 5360 | Loss: 0.48651, Accuracy: 77.03% | Test loss: 0.48531, Test acc: 77.53%\n",
      "Epoch: 5370 | Loss: 0.48651, Accuracy: 77.03% | Test loss: 0.48531, Test acc: 77.53%\n",
      "Epoch: 5380 | Loss: 0.48650, Accuracy: 77.03% | Test loss: 0.48530, Test acc: 77.53%\n",
      "Epoch: 5390 | Loss: 0.48649, Accuracy: 77.03% | Test loss: 0.48530, Test acc: 77.53%\n",
      "Epoch: 5400 | Loss: 0.48649, Accuracy: 77.03% | Test loss: 0.48529, Test acc: 77.53%\n",
      "Epoch: 5410 | Loss: 0.48648, Accuracy: 77.03% | Test loss: 0.48529, Test acc: 77.53%\n",
      "Epoch: 5420 | Loss: 0.48648, Accuracy: 77.03% | Test loss: 0.48529, Test acc: 77.53%\n",
      "Epoch: 5430 | Loss: 0.48647, Accuracy: 77.03% | Test loss: 0.48528, Test acc: 77.53%\n",
      "Epoch: 5440 | Loss: 0.48647, Accuracy: 77.03% | Test loss: 0.48528, Test acc: 77.53%\n",
      "Epoch: 5450 | Loss: 0.48647, Accuracy: 77.04% | Test loss: 0.48527, Test acc: 77.53%\n",
      "Epoch: 5460 | Loss: 0.48646, Accuracy: 77.04% | Test loss: 0.48527, Test acc: 77.53%\n",
      "Epoch: 5470 | Loss: 0.48646, Accuracy: 77.04% | Test loss: 0.48526, Test acc: 77.53%\n",
      "Epoch: 5480 | Loss: 0.48645, Accuracy: 77.04% | Test loss: 0.48526, Test acc: 77.53%\n",
      "Epoch: 5490 | Loss: 0.48645, Accuracy: 77.04% | Test loss: 0.48526, Test acc: 77.53%\n",
      "Epoch: 5500 | Loss: 0.48644, Accuracy: 77.04% | Test loss: 0.48525, Test acc: 77.53%\n",
      "Epoch: 5510 | Loss: 0.48644, Accuracy: 77.04% | Test loss: 0.48525, Test acc: 77.53%\n",
      "Epoch: 5520 | Loss: 0.48643, Accuracy: 77.04% | Test loss: 0.48524, Test acc: 77.53%\n",
      "Epoch: 5530 | Loss: 0.48643, Accuracy: 77.04% | Test loss: 0.48524, Test acc: 77.53%\n",
      "Epoch: 5540 | Loss: 0.48642, Accuracy: 77.04% | Test loss: 0.48523, Test acc: 77.53%\n",
      "Epoch: 5550 | Loss: 0.48642, Accuracy: 77.04% | Test loss: 0.48523, Test acc: 77.53%\n",
      "Epoch: 5560 | Loss: 0.48641, Accuracy: 77.04% | Test loss: 0.48523, Test acc: 77.53%\n",
      "Epoch: 5570 | Loss: 0.48641, Accuracy: 77.04% | Test loss: 0.48522, Test acc: 77.53%\n",
      "Epoch: 5580 | Loss: 0.48640, Accuracy: 77.04% | Test loss: 0.48522, Test acc: 77.53%\n",
      "Epoch: 5590 | Loss: 0.48640, Accuracy: 77.04% | Test loss: 0.48521, Test acc: 77.53%\n",
      "Epoch: 5600 | Loss: 0.48639, Accuracy: 77.04% | Test loss: 0.48521, Test acc: 77.53%\n",
      "Epoch: 5610 | Loss: 0.48639, Accuracy: 77.04% | Test loss: 0.48521, Test acc: 77.53%\n",
      "Epoch: 5620 | Loss: 0.48638, Accuracy: 77.04% | Test loss: 0.48520, Test acc: 77.53%\n",
      "Epoch: 5630 | Loss: 0.48638, Accuracy: 77.04% | Test loss: 0.48520, Test acc: 77.53%\n",
      "Epoch: 5640 | Loss: 0.48637, Accuracy: 77.04% | Test loss: 0.48519, Test acc: 77.53%\n",
      "Epoch: 5650 | Loss: 0.48637, Accuracy: 77.04% | Test loss: 0.48519, Test acc: 77.53%\n",
      "Epoch: 5660 | Loss: 0.48636, Accuracy: 77.04% | Test loss: 0.48518, Test acc: 77.53%\n",
      "Epoch: 5670 | Loss: 0.48636, Accuracy: 77.04% | Test loss: 0.48518, Test acc: 77.53%\n",
      "Epoch: 5680 | Loss: 0.48635, Accuracy: 77.04% | Test loss: 0.48518, Test acc: 77.53%\n",
      "Epoch: 5690 | Loss: 0.48635, Accuracy: 77.04% | Test loss: 0.48517, Test acc: 77.53%\n",
      "Epoch: 5700 | Loss: 0.48634, Accuracy: 77.04% | Test loss: 0.48517, Test acc: 77.53%\n",
      "Epoch: 5710 | Loss: 0.48634, Accuracy: 77.04% | Test loss: 0.48516, Test acc: 77.53%\n",
      "Epoch: 5720 | Loss: 0.48633, Accuracy: 77.04% | Test loss: 0.48516, Test acc: 77.53%\n",
      "Epoch: 5730 | Loss: 0.48633, Accuracy: 77.04% | Test loss: 0.48516, Test acc: 77.53%\n",
      "Epoch: 5740 | Loss: 0.48632, Accuracy: 77.04% | Test loss: 0.48515, Test acc: 77.53%\n",
      "Epoch: 5750 | Loss: 0.48632, Accuracy: 77.04% | Test loss: 0.48515, Test acc: 77.53%\n",
      "Epoch: 5760 | Loss: 0.48631, Accuracy: 77.04% | Test loss: 0.48514, Test acc: 77.53%\n",
      "Epoch: 5770 | Loss: 0.48631, Accuracy: 77.04% | Test loss: 0.48514, Test acc: 77.53%\n",
      "Epoch: 5780 | Loss: 0.48630, Accuracy: 77.04% | Test loss: 0.48513, Test acc: 77.53%\n",
      "Epoch: 5790 | Loss: 0.48630, Accuracy: 77.04% | Test loss: 0.48513, Test acc: 77.53%\n",
      "Epoch: 5800 | Loss: 0.48629, Accuracy: 77.04% | Test loss: 0.48513, Test acc: 77.53%\n",
      "Epoch: 5810 | Loss: 0.48629, Accuracy: 77.04% | Test loss: 0.48512, Test acc: 77.53%\n",
      "Epoch: 5820 | Loss: 0.48628, Accuracy: 77.04% | Test loss: 0.48512, Test acc: 77.53%\n",
      "Epoch: 5830 | Loss: 0.48628, Accuracy: 77.04% | Test loss: 0.48511, Test acc: 77.53%\n",
      "Epoch: 5840 | Loss: 0.48627, Accuracy: 77.04% | Test loss: 0.48511, Test acc: 77.53%\n",
      "Epoch: 5850 | Loss: 0.48627, Accuracy: 77.04% | Test loss: 0.48511, Test acc: 77.53%\n",
      "Epoch: 5860 | Loss: 0.48626, Accuracy: 77.06% | Test loss: 0.48510, Test acc: 77.53%\n",
      "Epoch: 5870 | Loss: 0.48626, Accuracy: 77.06% | Test loss: 0.48510, Test acc: 77.53%\n",
      "Epoch: 5880 | Loss: 0.48625, Accuracy: 77.06% | Test loss: 0.48509, Test acc: 77.53%\n",
      "Epoch: 5890 | Loss: 0.48625, Accuracy: 77.06% | Test loss: 0.48509, Test acc: 77.53%\n",
      "Epoch: 5900 | Loss: 0.48624, Accuracy: 77.06% | Test loss: 0.48508, Test acc: 77.53%\n",
      "Epoch: 5910 | Loss: 0.48624, Accuracy: 77.06% | Test loss: 0.48508, Test acc: 77.53%\n",
      "Epoch: 5920 | Loss: 0.48623, Accuracy: 77.06% | Test loss: 0.48508, Test acc: 77.53%\n",
      "Epoch: 5930 | Loss: 0.48623, Accuracy: 77.06% | Test loss: 0.48507, Test acc: 77.53%\n",
      "Epoch: 5940 | Loss: 0.48622, Accuracy: 77.07% | Test loss: 0.48507, Test acc: 77.53%\n",
      "Epoch: 5950 | Loss: 0.48622, Accuracy: 77.07% | Test loss: 0.48506, Test acc: 77.53%\n",
      "Epoch: 5960 | Loss: 0.48621, Accuracy: 77.07% | Test loss: 0.48506, Test acc: 77.53%\n",
      "Epoch: 5970 | Loss: 0.48621, Accuracy: 77.11% | Test loss: 0.48506, Test acc: 77.55%\n",
      "Epoch: 5980 | Loss: 0.48620, Accuracy: 77.11% | Test loss: 0.48505, Test acc: 77.55%\n",
      "Epoch: 5990 | Loss: 0.48620, Accuracy: 77.11% | Test loss: 0.48505, Test acc: 77.55%\n",
      "Epoch: 6000 | Loss: 0.48620, Accuracy: 77.11% | Test loss: 0.48504, Test acc: 77.55%\n",
      "Epoch: 6010 | Loss: 0.48619, Accuracy: 77.11% | Test loss: 0.48504, Test acc: 77.55%\n",
      "Epoch: 6020 | Loss: 0.48619, Accuracy: 77.10% | Test loss: 0.48503, Test acc: 77.55%\n",
      "Epoch: 6030 | Loss: 0.48618, Accuracy: 77.10% | Test loss: 0.48503, Test acc: 77.55%\n",
      "Epoch: 6040 | Loss: 0.48618, Accuracy: 77.10% | Test loss: 0.48503, Test acc: 77.55%\n",
      "Epoch: 6050 | Loss: 0.48617, Accuracy: 77.10% | Test loss: 0.48502, Test acc: 77.55%\n",
      "Epoch: 6060 | Loss: 0.48617, Accuracy: 77.10% | Test loss: 0.48502, Test acc: 77.55%\n",
      "Epoch: 6070 | Loss: 0.48616, Accuracy: 77.10% | Test loss: 0.48501, Test acc: 77.55%\n",
      "Epoch: 6080 | Loss: 0.48616, Accuracy: 77.11% | Test loss: 0.48501, Test acc: 77.55%\n",
      "Epoch: 6090 | Loss: 0.48615, Accuracy: 77.11% | Test loss: 0.48501, Test acc: 77.55%\n",
      "Epoch: 6100 | Loss: 0.48615, Accuracy: 77.11% | Test loss: 0.48500, Test acc: 77.55%\n",
      "Epoch: 6110 | Loss: 0.48614, Accuracy: 77.11% | Test loss: 0.48500, Test acc: 77.55%\n",
      "Epoch: 6120 | Loss: 0.48614, Accuracy: 77.11% | Test loss: 0.48499, Test acc: 77.55%\n",
      "Epoch: 6130 | Loss: 0.48613, Accuracy: 77.11% | Test loss: 0.48499, Test acc: 77.55%\n",
      "Epoch: 6140 | Loss: 0.48613, Accuracy: 77.11% | Test loss: 0.48499, Test acc: 77.55%\n",
      "Epoch: 6150 | Loss: 0.48612, Accuracy: 77.11% | Test loss: 0.48498, Test acc: 77.55%\n",
      "Epoch: 6160 | Loss: 0.48612, Accuracy: 77.11% | Test loss: 0.48498, Test acc: 77.55%\n",
      "Epoch: 6170 | Loss: 0.48611, Accuracy: 77.11% | Test loss: 0.48497, Test acc: 77.55%\n",
      "Epoch: 6180 | Loss: 0.48611, Accuracy: 77.11% | Test loss: 0.48497, Test acc: 77.55%\n",
      "Epoch: 6190 | Loss: 0.48610, Accuracy: 77.11% | Test loss: 0.48496, Test acc: 77.55%\n",
      "Epoch: 6200 | Loss: 0.48610, Accuracy: 77.11% | Test loss: 0.48496, Test acc: 77.55%\n",
      "Epoch: 6210 | Loss: 0.48609, Accuracy: 77.11% | Test loss: 0.48496, Test acc: 77.55%\n",
      "Epoch: 6220 | Loss: 0.48609, Accuracy: 77.11% | Test loss: 0.48495, Test acc: 77.55%\n",
      "Epoch: 6230 | Loss: 0.48608, Accuracy: 77.11% | Test loss: 0.48495, Test acc: 77.55%\n",
      "Epoch: 6240 | Loss: 0.48608, Accuracy: 77.10% | Test loss: 0.48494, Test acc: 77.55%\n",
      "Epoch: 6250 | Loss: 0.48607, Accuracy: 77.10% | Test loss: 0.48494, Test acc: 77.55%\n",
      "Epoch: 6260 | Loss: 0.48607, Accuracy: 77.10% | Test loss: 0.48494, Test acc: 77.55%\n",
      "Epoch: 6270 | Loss: 0.48606, Accuracy: 77.10% | Test loss: 0.48493, Test acc: 77.55%\n",
      "Epoch: 6280 | Loss: 0.48606, Accuracy: 77.10% | Test loss: 0.48493, Test acc: 77.55%\n",
      "Epoch: 6290 | Loss: 0.48606, Accuracy: 77.10% | Test loss: 0.48492, Test acc: 77.55%\n",
      "Epoch: 6300 | Loss: 0.48605, Accuracy: 77.11% | Test loss: 0.48492, Test acc: 77.53%\n",
      "Epoch: 6310 | Loss: 0.48605, Accuracy: 77.11% | Test loss: 0.48492, Test acc: 77.53%\n",
      "Epoch: 6320 | Loss: 0.48604, Accuracy: 77.11% | Test loss: 0.48491, Test acc: 77.53%\n",
      "Epoch: 6330 | Loss: 0.48604, Accuracy: 77.11% | Test loss: 0.48491, Test acc: 77.53%\n",
      "Epoch: 6340 | Loss: 0.48603, Accuracy: 77.11% | Test loss: 0.48490, Test acc: 77.53%\n",
      "Epoch: 6350 | Loss: 0.48603, Accuracy: 77.11% | Test loss: 0.48490, Test acc: 77.53%\n",
      "Epoch: 6360 | Loss: 0.48602, Accuracy: 77.11% | Test loss: 0.48490, Test acc: 77.53%\n",
      "Epoch: 6370 | Loss: 0.48602, Accuracy: 77.11% | Test loss: 0.48489, Test acc: 77.55%\n",
      "Epoch: 6380 | Loss: 0.48601, Accuracy: 77.11% | Test loss: 0.48489, Test acc: 77.55%\n",
      "Epoch: 6390 | Loss: 0.48601, Accuracy: 77.11% | Test loss: 0.48488, Test acc: 77.55%\n",
      "Epoch: 6400 | Loss: 0.48600, Accuracy: 77.11% | Test loss: 0.48488, Test acc: 77.55%\n",
      "Epoch: 6410 | Loss: 0.48600, Accuracy: 77.11% | Test loss: 0.48487, Test acc: 77.55%\n",
      "Epoch: 6420 | Loss: 0.48599, Accuracy: 77.10% | Test loss: 0.48487, Test acc: 77.55%\n",
      "Epoch: 6430 | Loss: 0.48599, Accuracy: 77.10% | Test loss: 0.48487, Test acc: 77.55%\n",
      "Epoch: 6440 | Loss: 0.48598, Accuracy: 77.10% | Test loss: 0.48486, Test acc: 77.55%\n",
      "Epoch: 6450 | Loss: 0.48598, Accuracy: 77.10% | Test loss: 0.48486, Test acc: 77.55%\n",
      "Epoch: 6460 | Loss: 0.48597, Accuracy: 77.10% | Test loss: 0.48485, Test acc: 77.55%\n",
      "Epoch: 6470 | Loss: 0.48597, Accuracy: 77.10% | Test loss: 0.48485, Test acc: 77.55%\n",
      "Epoch: 6480 | Loss: 0.48596, Accuracy: 77.10% | Test loss: 0.48485, Test acc: 77.55%\n",
      "Epoch: 6490 | Loss: 0.48596, Accuracy: 77.10% | Test loss: 0.48484, Test acc: 77.55%\n",
      "Epoch: 6500 | Loss: 0.48595, Accuracy: 77.10% | Test loss: 0.48484, Test acc: 77.55%\n",
      "Epoch: 6510 | Loss: 0.48595, Accuracy: 77.10% | Test loss: 0.48483, Test acc: 77.55%\n",
      "Epoch: 6520 | Loss: 0.48595, Accuracy: 77.10% | Test loss: 0.48483, Test acc: 77.55%\n",
      "Epoch: 6530 | Loss: 0.48594, Accuracy: 77.10% | Test loss: 0.48483, Test acc: 77.55%\n",
      "Epoch: 6540 | Loss: 0.48594, Accuracy: 77.10% | Test loss: 0.48482, Test acc: 77.55%\n",
      "Epoch: 6550 | Loss: 0.48593, Accuracy: 77.09% | Test loss: 0.48482, Test acc: 77.55%\n",
      "Epoch: 6560 | Loss: 0.48593, Accuracy: 77.09% | Test loss: 0.48481, Test acc: 77.55%\n",
      "Epoch: 6570 | Loss: 0.48592, Accuracy: 77.09% | Test loss: 0.48481, Test acc: 77.55%\n",
      "Epoch: 6580 | Loss: 0.48592, Accuracy: 77.09% | Test loss: 0.48481, Test acc: 77.55%\n",
      "Epoch: 6590 | Loss: 0.48591, Accuracy: 77.09% | Test loss: 0.48480, Test acc: 77.55%\n",
      "Epoch: 6600 | Loss: 0.48591, Accuracy: 77.09% | Test loss: 0.48480, Test acc: 77.55%\n",
      "Epoch: 6610 | Loss: 0.48590, Accuracy: 77.09% | Test loss: 0.48479, Test acc: 77.55%\n",
      "Epoch: 6620 | Loss: 0.48590, Accuracy: 77.09% | Test loss: 0.48479, Test acc: 77.55%\n",
      "Epoch: 6630 | Loss: 0.48589, Accuracy: 77.09% | Test loss: 0.48479, Test acc: 77.55%\n",
      "Epoch: 6640 | Loss: 0.48589, Accuracy: 77.09% | Test loss: 0.48478, Test acc: 77.55%\n",
      "Epoch: 6650 | Loss: 0.48588, Accuracy: 77.09% | Test loss: 0.48478, Test acc: 77.55%\n",
      "Epoch: 6660 | Loss: 0.48588, Accuracy: 77.09% | Test loss: 0.48477, Test acc: 77.55%\n",
      "Epoch: 6670 | Loss: 0.48587, Accuracy: 77.09% | Test loss: 0.48477, Test acc: 77.55%\n",
      "Epoch: 6680 | Loss: 0.48587, Accuracy: 77.09% | Test loss: 0.48477, Test acc: 77.55%\n",
      "Epoch: 6690 | Loss: 0.48586, Accuracy: 77.09% | Test loss: 0.48476, Test acc: 77.55%\n",
      "Epoch: 6700 | Loss: 0.48586, Accuracy: 77.09% | Test loss: 0.48476, Test acc: 77.55%\n",
      "Epoch: 6710 | Loss: 0.48586, Accuracy: 77.09% | Test loss: 0.48475, Test acc: 77.55%\n",
      "Epoch: 6720 | Loss: 0.48585, Accuracy: 77.09% | Test loss: 0.48475, Test acc: 77.55%\n",
      "Epoch: 6730 | Loss: 0.48585, Accuracy: 77.09% | Test loss: 0.48475, Test acc: 77.55%\n",
      "Epoch: 6740 | Loss: 0.48584, Accuracy: 77.09% | Test loss: 0.48474, Test acc: 77.55%\n",
      "Epoch: 6750 | Loss: 0.48584, Accuracy: 77.09% | Test loss: 0.48474, Test acc: 77.55%\n",
      "Epoch: 6760 | Loss: 0.48583, Accuracy: 77.09% | Test loss: 0.48473, Test acc: 77.55%\n",
      "Epoch: 6770 | Loss: 0.48583, Accuracy: 77.09% | Test loss: 0.48473, Test acc: 77.55%\n",
      "Epoch: 6780 | Loss: 0.48582, Accuracy: 77.09% | Test loss: 0.48473, Test acc: 77.55%\n",
      "Epoch: 6790 | Loss: 0.48582, Accuracy: 77.09% | Test loss: 0.48472, Test acc: 77.55%\n",
      "Epoch: 6800 | Loss: 0.48581, Accuracy: 77.09% | Test loss: 0.48472, Test acc: 77.55%\n",
      "Epoch: 6810 | Loss: 0.48581, Accuracy: 77.09% | Test loss: 0.48471, Test acc: 77.55%\n",
      "Epoch: 6820 | Loss: 0.48580, Accuracy: 77.09% | Test loss: 0.48471, Test acc: 77.55%\n",
      "Epoch: 6830 | Loss: 0.48580, Accuracy: 77.09% | Test loss: 0.48471, Test acc: 77.55%\n",
      "Epoch: 6840 | Loss: 0.48579, Accuracy: 77.09% | Test loss: 0.48470, Test acc: 77.55%\n",
      "Epoch: 6850 | Loss: 0.48579, Accuracy: 77.09% | Test loss: 0.48470, Test acc: 77.55%\n",
      "Epoch: 6860 | Loss: 0.48578, Accuracy: 77.09% | Test loss: 0.48469, Test acc: 77.55%\n",
      "Epoch: 6870 | Loss: 0.48578, Accuracy: 77.09% | Test loss: 0.48469, Test acc: 77.55%\n",
      "Epoch: 6880 | Loss: 0.48577, Accuracy: 77.09% | Test loss: 0.48468, Test acc: 77.55%\n",
      "Epoch: 6890 | Loss: 0.48577, Accuracy: 77.09% | Test loss: 0.48468, Test acc: 77.55%\n",
      "Epoch: 6900 | Loss: 0.48577, Accuracy: 77.09% | Test loss: 0.48468, Test acc: 77.55%\n",
      "Epoch: 6910 | Loss: 0.48576, Accuracy: 77.09% | Test loss: 0.48467, Test acc: 77.55%\n",
      "Epoch: 6920 | Loss: 0.48576, Accuracy: 77.09% | Test loss: 0.48467, Test acc: 77.55%\n",
      "Epoch: 6930 | Loss: 0.48575, Accuracy: 77.09% | Test loss: 0.48466, Test acc: 77.55%\n",
      "Epoch: 6940 | Loss: 0.48575, Accuracy: 77.09% | Test loss: 0.48466, Test acc: 77.55%\n",
      "Epoch: 6950 | Loss: 0.48574, Accuracy: 77.09% | Test loss: 0.48466, Test acc: 77.55%\n",
      "Epoch: 6960 | Loss: 0.48574, Accuracy: 77.09% | Test loss: 0.48465, Test acc: 77.55%\n",
      "Epoch: 6970 | Loss: 0.48573, Accuracy: 77.09% | Test loss: 0.48465, Test acc: 77.55%\n",
      "Epoch: 6980 | Loss: 0.48573, Accuracy: 77.09% | Test loss: 0.48465, Test acc: 77.55%\n",
      "Epoch: 6990 | Loss: 0.48572, Accuracy: 77.09% | Test loss: 0.48464, Test acc: 77.55%\n",
      "Epoch: 7000 | Loss: 0.48572, Accuracy: 77.09% | Test loss: 0.48464, Test acc: 77.55%\n",
      "Epoch: 7010 | Loss: 0.48571, Accuracy: 77.09% | Test loss: 0.48463, Test acc: 77.55%\n",
      "Epoch: 7020 | Loss: 0.48571, Accuracy: 77.09% | Test loss: 0.48463, Test acc: 77.55%\n",
      "Epoch: 7030 | Loss: 0.48570, Accuracy: 77.09% | Test loss: 0.48462, Test acc: 77.55%\n",
      "Epoch: 7040 | Loss: 0.48570, Accuracy: 77.09% | Test loss: 0.48462, Test acc: 77.55%\n",
      "Epoch: 7050 | Loss: 0.48570, Accuracy: 77.09% | Test loss: 0.48462, Test acc: 77.55%\n",
      "Epoch: 7060 | Loss: 0.48569, Accuracy: 77.09% | Test loss: 0.48461, Test acc: 77.55%\n",
      "Epoch: 7070 | Loss: 0.48569, Accuracy: 77.09% | Test loss: 0.48461, Test acc: 77.55%\n",
      "Epoch: 7080 | Loss: 0.48568, Accuracy: 77.09% | Test loss: 0.48461, Test acc: 77.55%\n",
      "Epoch: 7090 | Loss: 0.48568, Accuracy: 77.09% | Test loss: 0.48460, Test acc: 77.55%\n",
      "Epoch: 7100 | Loss: 0.48567, Accuracy: 77.09% | Test loss: 0.48460, Test acc: 77.55%\n",
      "Epoch: 7110 | Loss: 0.48567, Accuracy: 77.09% | Test loss: 0.48459, Test acc: 77.55%\n",
      "Epoch: 7120 | Loss: 0.48566, Accuracy: 77.09% | Test loss: 0.48459, Test acc: 77.55%\n",
      "Epoch: 7130 | Loss: 0.48566, Accuracy: 77.09% | Test loss: 0.48459, Test acc: 77.55%\n",
      "Epoch: 7140 | Loss: 0.48565, Accuracy: 77.09% | Test loss: 0.48458, Test acc: 77.55%\n",
      "Epoch: 7150 | Loss: 0.48565, Accuracy: 77.09% | Test loss: 0.48458, Test acc: 77.55%\n",
      "Epoch: 7160 | Loss: 0.48564, Accuracy: 77.09% | Test loss: 0.48457, Test acc: 77.55%\n",
      "Epoch: 7170 | Loss: 0.48564, Accuracy: 77.09% | Test loss: 0.48457, Test acc: 77.55%\n",
      "Epoch: 7180 | Loss: 0.48563, Accuracy: 77.09% | Test loss: 0.48457, Test acc: 77.55%\n",
      "Epoch: 7190 | Loss: 0.48563, Accuracy: 77.09% | Test loss: 0.48456, Test acc: 77.55%\n",
      "Epoch: 7200 | Loss: 0.48563, Accuracy: 77.09% | Test loss: 0.48456, Test acc: 77.55%\n",
      "Epoch: 7210 | Loss: 0.48562, Accuracy: 77.09% | Test loss: 0.48455, Test acc: 77.55%\n",
      "Epoch: 7220 | Loss: 0.48562, Accuracy: 77.09% | Test loss: 0.48455, Test acc: 77.55%\n",
      "Epoch: 7230 | Loss: 0.48561, Accuracy: 77.09% | Test loss: 0.48455, Test acc: 77.55%\n",
      "Epoch: 7240 | Loss: 0.48561, Accuracy: 77.09% | Test loss: 0.48454, Test acc: 77.55%\n",
      "Epoch: 7250 | Loss: 0.48560, Accuracy: 77.09% | Test loss: 0.48454, Test acc: 77.55%\n",
      "Epoch: 7260 | Loss: 0.48560, Accuracy: 77.09% | Test loss: 0.48453, Test acc: 77.55%\n",
      "Epoch: 7270 | Loss: 0.48559, Accuracy: 77.09% | Test loss: 0.48453, Test acc: 77.55%\n",
      "Epoch: 7280 | Loss: 0.48559, Accuracy: 77.09% | Test loss: 0.48453, Test acc: 77.55%\n",
      "Epoch: 7290 | Loss: 0.48558, Accuracy: 77.09% | Test loss: 0.48452, Test acc: 77.55%\n",
      "Epoch: 7300 | Loss: 0.48558, Accuracy: 77.09% | Test loss: 0.48452, Test acc: 77.58%\n",
      "Epoch: 7310 | Loss: 0.48557, Accuracy: 77.09% | Test loss: 0.48451, Test acc: 77.58%\n",
      "Epoch: 7320 | Loss: 0.48557, Accuracy: 77.09% | Test loss: 0.48451, Test acc: 77.58%\n",
      "Epoch: 7330 | Loss: 0.48557, Accuracy: 77.09% | Test loss: 0.48451, Test acc: 77.58%\n",
      "Epoch: 7340 | Loss: 0.48556, Accuracy: 77.09% | Test loss: 0.48450, Test acc: 77.58%\n",
      "Epoch: 7350 | Loss: 0.48556, Accuracy: 77.09% | Test loss: 0.48450, Test acc: 77.58%\n",
      "Epoch: 7360 | Loss: 0.48555, Accuracy: 77.09% | Test loss: 0.48449, Test acc: 77.58%\n",
      "Epoch: 7370 | Loss: 0.48555, Accuracy: 77.09% | Test loss: 0.48449, Test acc: 77.58%\n",
      "Epoch: 7380 | Loss: 0.48554, Accuracy: 77.09% | Test loss: 0.48449, Test acc: 77.58%\n",
      "Epoch: 7390 | Loss: 0.48554, Accuracy: 77.09% | Test loss: 0.48448, Test acc: 77.58%\n",
      "Epoch: 7400 | Loss: 0.48553, Accuracy: 77.09% | Test loss: 0.48448, Test acc: 77.58%\n",
      "Epoch: 7410 | Loss: 0.48553, Accuracy: 77.09% | Test loss: 0.48447, Test acc: 77.58%\n",
      "Epoch: 7420 | Loss: 0.48552, Accuracy: 77.09% | Test loss: 0.48447, Test acc: 77.58%\n",
      "Epoch: 7430 | Loss: 0.48552, Accuracy: 77.10% | Test loss: 0.48447, Test acc: 77.58%\n",
      "Epoch: 7440 | Loss: 0.48551, Accuracy: 77.09% | Test loss: 0.48446, Test acc: 77.58%\n",
      "Epoch: 7450 | Loss: 0.48551, Accuracy: 77.09% | Test loss: 0.48446, Test acc: 77.58%\n",
      "Epoch: 7460 | Loss: 0.48551, Accuracy: 77.09% | Test loss: 0.48445, Test acc: 77.58%\n",
      "Epoch: 7470 | Loss: 0.48550, Accuracy: 77.09% | Test loss: 0.48445, Test acc: 77.58%\n",
      "Epoch: 7480 | Loss: 0.48550, Accuracy: 77.09% | Test loss: 0.48445, Test acc: 77.58%\n",
      "Epoch: 7490 | Loss: 0.48549, Accuracy: 77.09% | Test loss: 0.48444, Test acc: 77.58%\n",
      "Epoch: 7500 | Loss: 0.48549, Accuracy: 77.09% | Test loss: 0.48444, Test acc: 77.58%\n",
      "Epoch: 7510 | Loss: 0.48548, Accuracy: 77.09% | Test loss: 0.48444, Test acc: 77.58%\n",
      "Epoch: 7520 | Loss: 0.48548, Accuracy: 77.09% | Test loss: 0.48443, Test acc: 77.58%\n",
      "Epoch: 7530 | Loss: 0.48547, Accuracy: 77.09% | Test loss: 0.48443, Test acc: 77.58%\n",
      "Epoch: 7540 | Loss: 0.48547, Accuracy: 77.09% | Test loss: 0.48442, Test acc: 77.58%\n",
      "Epoch: 7550 | Loss: 0.48546, Accuracy: 77.09% | Test loss: 0.48442, Test acc: 77.58%\n",
      "Epoch: 7560 | Loss: 0.48546, Accuracy: 77.09% | Test loss: 0.48442, Test acc: 77.58%\n",
      "Epoch: 7570 | Loss: 0.48545, Accuracy: 77.09% | Test loss: 0.48441, Test acc: 77.58%\n",
      "Epoch: 7580 | Loss: 0.48545, Accuracy: 77.09% | Test loss: 0.48441, Test acc: 77.58%\n",
      "Epoch: 7590 | Loss: 0.48545, Accuracy: 77.09% | Test loss: 0.48440, Test acc: 77.58%\n",
      "Epoch: 7600 | Loss: 0.48544, Accuracy: 77.09% | Test loss: 0.48440, Test acc: 77.58%\n",
      "Epoch: 7610 | Loss: 0.48544, Accuracy: 77.09% | Test loss: 0.48440, Test acc: 77.58%\n",
      "Epoch: 7620 | Loss: 0.48543, Accuracy: 77.09% | Test loss: 0.48439, Test acc: 77.58%\n",
      "Epoch: 7630 | Loss: 0.48543, Accuracy: 77.09% | Test loss: 0.48439, Test acc: 77.58%\n",
      "Epoch: 7640 | Loss: 0.48542, Accuracy: 77.09% | Test loss: 0.48438, Test acc: 77.58%\n",
      "Epoch: 7650 | Loss: 0.48542, Accuracy: 77.10% | Test loss: 0.48438, Test acc: 77.58%\n",
      "Epoch: 7660 | Loss: 0.48541, Accuracy: 77.10% | Test loss: 0.48438, Test acc: 77.58%\n",
      "Epoch: 7670 | Loss: 0.48541, Accuracy: 77.10% | Test loss: 0.48437, Test acc: 77.58%\n",
      "Epoch: 7680 | Loss: 0.48540, Accuracy: 77.10% | Test loss: 0.48437, Test acc: 77.58%\n",
      "Epoch: 7690 | Loss: 0.48540, Accuracy: 77.09% | Test loss: 0.48437, Test acc: 77.58%\n",
      "Epoch: 7700 | Loss: 0.48540, Accuracy: 77.09% | Test loss: 0.48436, Test acc: 77.58%\n",
      "Epoch: 7710 | Loss: 0.48539, Accuracy: 77.09% | Test loss: 0.48436, Test acc: 77.58%\n",
      "Epoch: 7720 | Loss: 0.48539, Accuracy: 77.09% | Test loss: 0.48435, Test acc: 77.58%\n",
      "Epoch: 7730 | Loss: 0.48538, Accuracy: 77.09% | Test loss: 0.48435, Test acc: 77.58%\n",
      "Epoch: 7740 | Loss: 0.48538, Accuracy: 77.09% | Test loss: 0.48435, Test acc: 77.58%\n",
      "Epoch: 7750 | Loss: 0.48537, Accuracy: 77.09% | Test loss: 0.48434, Test acc: 77.58%\n",
      "Epoch: 7760 | Loss: 0.48537, Accuracy: 77.09% | Test loss: 0.48434, Test acc: 77.58%\n",
      "Epoch: 7770 | Loss: 0.48536, Accuracy: 77.09% | Test loss: 0.48433, Test acc: 77.58%\n",
      "Epoch: 7780 | Loss: 0.48536, Accuracy: 77.09% | Test loss: 0.48433, Test acc: 77.58%\n",
      "Epoch: 7790 | Loss: 0.48535, Accuracy: 77.09% | Test loss: 0.48433, Test acc: 77.58%\n",
      "Epoch: 7800 | Loss: 0.48535, Accuracy: 77.09% | Test loss: 0.48432, Test acc: 77.58%\n",
      "Epoch: 7810 | Loss: 0.48535, Accuracy: 77.09% | Test loss: 0.48432, Test acc: 77.58%\n",
      "Epoch: 7820 | Loss: 0.48534, Accuracy: 77.09% | Test loss: 0.48431, Test acc: 77.58%\n",
      "Epoch: 7830 | Loss: 0.48534, Accuracy: 77.09% | Test loss: 0.48431, Test acc: 77.58%\n",
      "Epoch: 7840 | Loss: 0.48533, Accuracy: 77.09% | Test loss: 0.48431, Test acc: 77.58%\n",
      "Epoch: 7850 | Loss: 0.48533, Accuracy: 77.09% | Test loss: 0.48430, Test acc: 77.58%\n",
      "Epoch: 7860 | Loss: 0.48532, Accuracy: 77.09% | Test loss: 0.48430, Test acc: 77.58%\n",
      "Epoch: 7870 | Loss: 0.48532, Accuracy: 77.09% | Test loss: 0.48429, Test acc: 77.58%\n",
      "Epoch: 7880 | Loss: 0.48531, Accuracy: 77.09% | Test loss: 0.48429, Test acc: 77.58%\n",
      "Epoch: 7890 | Loss: 0.48531, Accuracy: 77.09% | Test loss: 0.48429, Test acc: 77.58%\n",
      "Epoch: 7900 | Loss: 0.48530, Accuracy: 77.09% | Test loss: 0.48428, Test acc: 77.58%\n",
      "Epoch: 7910 | Loss: 0.48530, Accuracy: 77.09% | Test loss: 0.48428, Test acc: 77.58%\n",
      "Epoch: 7920 | Loss: 0.48530, Accuracy: 77.09% | Test loss: 0.48428, Test acc: 77.58%\n",
      "Epoch: 7930 | Loss: 0.48529, Accuracy: 77.09% | Test loss: 0.48427, Test acc: 77.58%\n",
      "Epoch: 7940 | Loss: 0.48529, Accuracy: 77.09% | Test loss: 0.48427, Test acc: 77.58%\n",
      "Epoch: 7950 | Loss: 0.48528, Accuracy: 77.09% | Test loss: 0.48426, Test acc: 77.58%\n",
      "Epoch: 7960 | Loss: 0.48528, Accuracy: 77.09% | Test loss: 0.48426, Test acc: 77.58%\n",
      "Epoch: 7970 | Loss: 0.48527, Accuracy: 77.09% | Test loss: 0.48426, Test acc: 77.58%\n",
      "Epoch: 7980 | Loss: 0.48527, Accuracy: 77.09% | Test loss: 0.48425, Test acc: 77.58%\n",
      "Epoch: 7990 | Loss: 0.48526, Accuracy: 77.09% | Test loss: 0.48425, Test acc: 77.58%\n",
      "Epoch: 8000 | Loss: 0.48526, Accuracy: 77.09% | Test loss: 0.48424, Test acc: 77.58%\n",
      "Epoch: 8010 | Loss: 0.48525, Accuracy: 77.09% | Test loss: 0.48424, Test acc: 77.58%\n",
      "Epoch: 8020 | Loss: 0.48525, Accuracy: 77.09% | Test loss: 0.48424, Test acc: 77.58%\n",
      "Epoch: 8030 | Loss: 0.48525, Accuracy: 77.09% | Test loss: 0.48423, Test acc: 77.58%\n",
      "Epoch: 8040 | Loss: 0.48524, Accuracy: 77.09% | Test loss: 0.48423, Test acc: 77.58%\n",
      "Epoch: 8050 | Loss: 0.48524, Accuracy: 77.10% | Test loss: 0.48423, Test acc: 77.60%\n",
      "Epoch: 8060 | Loss: 0.48523, Accuracy: 77.10% | Test loss: 0.48422, Test acc: 77.60%\n",
      "Epoch: 8070 | Loss: 0.48523, Accuracy: 77.10% | Test loss: 0.48422, Test acc: 77.60%\n",
      "Epoch: 8080 | Loss: 0.48522, Accuracy: 77.10% | Test loss: 0.48421, Test acc: 77.60%\n",
      "Epoch: 8090 | Loss: 0.48522, Accuracy: 77.11% | Test loss: 0.48421, Test acc: 77.60%\n",
      "Epoch: 8100 | Loss: 0.48521, Accuracy: 77.11% | Test loss: 0.48421, Test acc: 77.60%\n",
      "Epoch: 8110 | Loss: 0.48521, Accuracy: 77.11% | Test loss: 0.48420, Test acc: 77.60%\n",
      "Epoch: 8120 | Loss: 0.48521, Accuracy: 77.11% | Test loss: 0.48420, Test acc: 77.60%\n",
      "Epoch: 8130 | Loss: 0.48520, Accuracy: 77.11% | Test loss: 0.48419, Test acc: 77.60%\n",
      "Epoch: 8140 | Loss: 0.48520, Accuracy: 77.11% | Test loss: 0.48419, Test acc: 77.60%\n",
      "Epoch: 8150 | Loss: 0.48519, Accuracy: 77.11% | Test loss: 0.48419, Test acc: 77.60%\n",
      "Epoch: 8160 | Loss: 0.48519, Accuracy: 77.11% | Test loss: 0.48418, Test acc: 77.60%\n",
      "Epoch: 8170 | Loss: 0.48518, Accuracy: 77.11% | Test loss: 0.48418, Test acc: 77.60%\n",
      "Epoch: 8180 | Loss: 0.48518, Accuracy: 77.11% | Test loss: 0.48418, Test acc: 77.60%\n",
      "Epoch: 8190 | Loss: 0.48517, Accuracy: 77.11% | Test loss: 0.48417, Test acc: 77.60%\n",
      "Epoch: 8200 | Loss: 0.48517, Accuracy: 77.11% | Test loss: 0.48417, Test acc: 77.60%\n",
      "Epoch: 8210 | Loss: 0.48516, Accuracy: 77.11% | Test loss: 0.48416, Test acc: 77.60%\n",
      "Epoch: 8220 | Loss: 0.48516, Accuracy: 77.11% | Test loss: 0.48416, Test acc: 77.60%\n",
      "Epoch: 8230 | Loss: 0.48516, Accuracy: 77.11% | Test loss: 0.48416, Test acc: 77.60%\n",
      "Epoch: 8240 | Loss: 0.48515, Accuracy: 77.11% | Test loss: 0.48415, Test acc: 77.60%\n",
      "Epoch: 8250 | Loss: 0.48515, Accuracy: 77.11% | Test loss: 0.48415, Test acc: 77.58%\n",
      "Epoch: 8260 | Loss: 0.48514, Accuracy: 77.11% | Test loss: 0.48415, Test acc: 77.58%\n",
      "Epoch: 8270 | Loss: 0.48514, Accuracy: 77.11% | Test loss: 0.48414, Test acc: 77.58%\n",
      "Epoch: 8280 | Loss: 0.48513, Accuracy: 77.11% | Test loss: 0.48414, Test acc: 77.58%\n",
      "Epoch: 8290 | Loss: 0.48513, Accuracy: 77.11% | Test loss: 0.48413, Test acc: 77.58%\n",
      "Epoch: 8300 | Loss: 0.48512, Accuracy: 77.11% | Test loss: 0.48413, Test acc: 77.58%\n",
      "Epoch: 8310 | Loss: 0.48512, Accuracy: 77.11% | Test loss: 0.48413, Test acc: 77.58%\n",
      "Epoch: 8320 | Loss: 0.48512, Accuracy: 77.11% | Test loss: 0.48412, Test acc: 77.58%\n",
      "Epoch: 8330 | Loss: 0.48511, Accuracy: 77.11% | Test loss: 0.48412, Test acc: 77.58%\n",
      "Epoch: 8340 | Loss: 0.48511, Accuracy: 77.11% | Test loss: 0.48411, Test acc: 77.58%\n",
      "Epoch: 8350 | Loss: 0.48510, Accuracy: 77.11% | Test loss: 0.48411, Test acc: 77.58%\n",
      "Epoch: 8360 | Loss: 0.48510, Accuracy: 77.11% | Test loss: 0.48411, Test acc: 77.58%\n",
      "Epoch: 8370 | Loss: 0.48509, Accuracy: 77.11% | Test loss: 0.48410, Test acc: 77.58%\n",
      "Epoch: 8380 | Loss: 0.48509, Accuracy: 77.11% | Test loss: 0.48410, Test acc: 77.58%\n",
      "Epoch: 8390 | Loss: 0.48508, Accuracy: 77.11% | Test loss: 0.48410, Test acc: 77.58%\n",
      "Epoch: 8400 | Loss: 0.48508, Accuracy: 77.14% | Test loss: 0.48409, Test acc: 77.58%\n",
      "Epoch: 8410 | Loss: 0.48508, Accuracy: 77.14% | Test loss: 0.48409, Test acc: 77.60%\n",
      "Epoch: 8420 | Loss: 0.48507, Accuracy: 77.14% | Test loss: 0.48408, Test acc: 77.60%\n",
      "Epoch: 8430 | Loss: 0.48507, Accuracy: 77.14% | Test loss: 0.48408, Test acc: 77.60%\n",
      "Epoch: 8440 | Loss: 0.48506, Accuracy: 77.14% | Test loss: 0.48408, Test acc: 77.60%\n",
      "Epoch: 8450 | Loss: 0.48506, Accuracy: 77.14% | Test loss: 0.48407, Test acc: 77.60%\n",
      "Epoch: 8460 | Loss: 0.48505, Accuracy: 77.14% | Test loss: 0.48407, Test acc: 77.60%\n",
      "Epoch: 8470 | Loss: 0.48505, Accuracy: 77.14% | Test loss: 0.48407, Test acc: 77.60%\n",
      "Epoch: 8480 | Loss: 0.48504, Accuracy: 77.14% | Test loss: 0.48406, Test acc: 77.60%\n",
      "Epoch: 8490 | Loss: 0.48504, Accuracy: 77.14% | Test loss: 0.48406, Test acc: 77.60%\n",
      "Epoch: 8500 | Loss: 0.48504, Accuracy: 77.14% | Test loss: 0.48405, Test acc: 77.60%\n",
      "Epoch: 8510 | Loss: 0.48503, Accuracy: 77.14% | Test loss: 0.48405, Test acc: 77.60%\n",
      "Epoch: 8520 | Loss: 0.48503, Accuracy: 77.14% | Test loss: 0.48405, Test acc: 77.60%\n",
      "Epoch: 8530 | Loss: 0.48502, Accuracy: 77.14% | Test loss: 0.48404, Test acc: 77.60%\n",
      "Epoch: 8540 | Loss: 0.48502, Accuracy: 77.14% | Test loss: 0.48404, Test acc: 77.60%\n",
      "Epoch: 8550 | Loss: 0.48501, Accuracy: 77.14% | Test loss: 0.48403, Test acc: 77.60%\n",
      "Epoch: 8560 | Loss: 0.48501, Accuracy: 77.14% | Test loss: 0.48403, Test acc: 77.60%\n",
      "Epoch: 8570 | Loss: 0.48500, Accuracy: 77.14% | Test loss: 0.48403, Test acc: 77.60%\n",
      "Epoch: 8580 | Loss: 0.48500, Accuracy: 77.14% | Test loss: 0.48402, Test acc: 77.60%\n",
      "Epoch: 8590 | Loss: 0.48500, Accuracy: 77.14% | Test loss: 0.48402, Test acc: 77.60%\n",
      "Epoch: 8600 | Loss: 0.48499, Accuracy: 77.14% | Test loss: 0.48402, Test acc: 77.60%\n",
      "Epoch: 8610 | Loss: 0.48499, Accuracy: 77.14% | Test loss: 0.48401, Test acc: 77.60%\n",
      "Epoch: 8620 | Loss: 0.48498, Accuracy: 77.14% | Test loss: 0.48401, Test acc: 77.60%\n",
      "Epoch: 8630 | Loss: 0.48498, Accuracy: 77.14% | Test loss: 0.48400, Test acc: 77.60%\n",
      "Epoch: 8640 | Loss: 0.48497, Accuracy: 77.14% | Test loss: 0.48400, Test acc: 77.60%\n",
      "Epoch: 8650 | Loss: 0.48497, Accuracy: 77.14% | Test loss: 0.48400, Test acc: 77.60%\n",
      "Epoch: 8660 | Loss: 0.48496, Accuracy: 77.14% | Test loss: 0.48399, Test acc: 77.60%\n",
      "Epoch: 8670 | Loss: 0.48496, Accuracy: 77.14% | Test loss: 0.48399, Test acc: 77.60%\n",
      "Epoch: 8680 | Loss: 0.48496, Accuracy: 77.14% | Test loss: 0.48399, Test acc: 77.60%\n",
      "Epoch: 8690 | Loss: 0.48495, Accuracy: 77.14% | Test loss: 0.48398, Test acc: 77.60%\n",
      "Epoch: 8700 | Loss: 0.48495, Accuracy: 77.14% | Test loss: 0.48398, Test acc: 77.60%\n",
      "Epoch: 8710 | Loss: 0.48494, Accuracy: 77.13% | Test loss: 0.48397, Test acc: 77.60%\n",
      "Epoch: 8720 | Loss: 0.48494, Accuracy: 77.13% | Test loss: 0.48397, Test acc: 77.60%\n",
      "Epoch: 8730 | Loss: 0.48493, Accuracy: 77.13% | Test loss: 0.48397, Test acc: 77.60%\n",
      "Epoch: 8740 | Loss: 0.48493, Accuracy: 77.13% | Test loss: 0.48396, Test acc: 77.60%\n",
      "Epoch: 8750 | Loss: 0.48492, Accuracy: 77.13% | Test loss: 0.48396, Test acc: 77.60%\n",
      "Epoch: 8760 | Loss: 0.48492, Accuracy: 77.13% | Test loss: 0.48396, Test acc: 77.60%\n",
      "Epoch: 8770 | Loss: 0.48492, Accuracy: 77.13% | Test loss: 0.48395, Test acc: 77.60%\n",
      "Epoch: 8780 | Loss: 0.48491, Accuracy: 77.14% | Test loss: 0.48395, Test acc: 77.60%\n",
      "Epoch: 8790 | Loss: 0.48491, Accuracy: 77.14% | Test loss: 0.48394, Test acc: 77.60%\n",
      "Epoch: 8800 | Loss: 0.48490, Accuracy: 77.14% | Test loss: 0.48394, Test acc: 77.60%\n",
      "Epoch: 8810 | Loss: 0.48490, Accuracy: 77.14% | Test loss: 0.48394, Test acc: 77.60%\n",
      "Epoch: 8820 | Loss: 0.48489, Accuracy: 77.14% | Test loss: 0.48393, Test acc: 77.60%\n",
      "Epoch: 8830 | Loss: 0.48489, Accuracy: 77.14% | Test loss: 0.48393, Test acc: 77.60%\n",
      "Epoch: 8840 | Loss: 0.48489, Accuracy: 77.14% | Test loss: 0.48393, Test acc: 77.60%\n",
      "Epoch: 8850 | Loss: 0.48488, Accuracy: 77.14% | Test loss: 0.48392, Test acc: 77.60%\n",
      "Epoch: 8860 | Loss: 0.48488, Accuracy: 77.14% | Test loss: 0.48392, Test acc: 77.60%\n",
      "Epoch: 8870 | Loss: 0.48487, Accuracy: 77.14% | Test loss: 0.48391, Test acc: 77.60%\n",
      "Epoch: 8880 | Loss: 0.48487, Accuracy: 77.14% | Test loss: 0.48391, Test acc: 77.60%\n",
      "Epoch: 8890 | Loss: 0.48486, Accuracy: 77.14% | Test loss: 0.48391, Test acc: 77.62%\n",
      "Epoch: 8900 | Loss: 0.48486, Accuracy: 77.14% | Test loss: 0.48390, Test acc: 77.62%\n",
      "Epoch: 8910 | Loss: 0.48485, Accuracy: 77.14% | Test loss: 0.48390, Test acc: 77.62%\n",
      "Epoch: 8920 | Loss: 0.48485, Accuracy: 77.14% | Test loss: 0.48390, Test acc: 77.62%\n",
      "Epoch: 8930 | Loss: 0.48485, Accuracy: 77.14% | Test loss: 0.48389, Test acc: 77.62%\n",
      "Epoch: 8940 | Loss: 0.48484, Accuracy: 77.14% | Test loss: 0.48389, Test acc: 77.62%\n",
      "Epoch: 8950 | Loss: 0.48484, Accuracy: 77.15% | Test loss: 0.48388, Test acc: 77.62%\n",
      "Epoch: 8960 | Loss: 0.48483, Accuracy: 77.15% | Test loss: 0.48388, Test acc: 77.62%\n",
      "Epoch: 8970 | Loss: 0.48483, Accuracy: 77.15% | Test loss: 0.48388, Test acc: 77.62%\n",
      "Epoch: 8980 | Loss: 0.48482, Accuracy: 77.15% | Test loss: 0.48387, Test acc: 77.62%\n",
      "Epoch: 8990 | Loss: 0.48482, Accuracy: 77.15% | Test loss: 0.48387, Test acc: 77.62%\n",
      "Epoch: 9000 | Loss: 0.48482, Accuracy: 77.15% | Test loss: 0.48387, Test acc: 77.62%\n",
      "Epoch: 9010 | Loss: 0.48481, Accuracy: 77.15% | Test loss: 0.48386, Test acc: 77.62%\n",
      "Epoch: 9020 | Loss: 0.48481, Accuracy: 77.15% | Test loss: 0.48386, Test acc: 77.60%\n",
      "Epoch: 9030 | Loss: 0.48480, Accuracy: 77.15% | Test loss: 0.48385, Test acc: 77.60%\n",
      "Epoch: 9040 | Loss: 0.48480, Accuracy: 77.14% | Test loss: 0.48385, Test acc: 77.60%\n",
      "Epoch: 9050 | Loss: 0.48479, Accuracy: 77.14% | Test loss: 0.48385, Test acc: 77.60%\n",
      "Epoch: 9060 | Loss: 0.48479, Accuracy: 77.14% | Test loss: 0.48384, Test acc: 77.60%\n",
      "Epoch: 9070 | Loss: 0.48479, Accuracy: 77.14% | Test loss: 0.48384, Test acc: 77.60%\n",
      "Epoch: 9080 | Loss: 0.48478, Accuracy: 77.14% | Test loss: 0.48384, Test acc: 77.60%\n",
      "Epoch: 9090 | Loss: 0.48478, Accuracy: 77.14% | Test loss: 0.48383, Test acc: 77.60%\n",
      "Epoch: 9100 | Loss: 0.48477, Accuracy: 77.14% | Test loss: 0.48383, Test acc: 77.60%\n",
      "Epoch: 9110 | Loss: 0.48477, Accuracy: 77.14% | Test loss: 0.48382, Test acc: 77.60%\n",
      "Epoch: 9120 | Loss: 0.48476, Accuracy: 77.14% | Test loss: 0.48382, Test acc: 77.60%\n",
      "Epoch: 9130 | Loss: 0.48476, Accuracy: 77.14% | Test loss: 0.48382, Test acc: 77.60%\n",
      "Epoch: 9140 | Loss: 0.48475, Accuracy: 77.14% | Test loss: 0.48381, Test acc: 77.60%\n",
      "Epoch: 9150 | Loss: 0.48475, Accuracy: 77.14% | Test loss: 0.48381, Test acc: 77.62%\n",
      "Epoch: 9160 | Loss: 0.48475, Accuracy: 77.14% | Test loss: 0.48381, Test acc: 77.62%\n",
      "Epoch: 9170 | Loss: 0.48474, Accuracy: 77.14% | Test loss: 0.48380, Test acc: 77.62%\n",
      "Epoch: 9180 | Loss: 0.48474, Accuracy: 77.14% | Test loss: 0.48380, Test acc: 77.62%\n",
      "Epoch: 9190 | Loss: 0.48473, Accuracy: 77.14% | Test loss: 0.48379, Test acc: 77.62%\n",
      "Epoch: 9200 | Loss: 0.48473, Accuracy: 77.14% | Test loss: 0.48379, Test acc: 77.62%\n",
      "Epoch: 9210 | Loss: 0.48472, Accuracy: 77.14% | Test loss: 0.48379, Test acc: 77.62%\n",
      "Epoch: 9220 | Loss: 0.48472, Accuracy: 77.14% | Test loss: 0.48378, Test acc: 77.62%\n",
      "Epoch: 9230 | Loss: 0.48472, Accuracy: 77.14% | Test loss: 0.48378, Test acc: 77.62%\n",
      "Epoch: 9240 | Loss: 0.48471, Accuracy: 77.14% | Test loss: 0.48378, Test acc: 77.60%\n",
      "Epoch: 9250 | Loss: 0.48471, Accuracy: 77.14% | Test loss: 0.48377, Test acc: 77.60%\n",
      "Epoch: 9260 | Loss: 0.48470, Accuracy: 77.14% | Test loss: 0.48377, Test acc: 77.60%\n",
      "Epoch: 9270 | Loss: 0.48470, Accuracy: 77.14% | Test loss: 0.48376, Test acc: 77.60%\n",
      "Epoch: 9280 | Loss: 0.48469, Accuracy: 77.14% | Test loss: 0.48376, Test acc: 77.60%\n",
      "Epoch: 9290 | Loss: 0.48469, Accuracy: 77.14% | Test loss: 0.48376, Test acc: 77.60%\n",
      "Epoch: 9300 | Loss: 0.48469, Accuracy: 77.14% | Test loss: 0.48375, Test acc: 77.60%\n",
      "Epoch: 9310 | Loss: 0.48468, Accuracy: 77.14% | Test loss: 0.48375, Test acc: 77.60%\n",
      "Epoch: 9320 | Loss: 0.48468, Accuracy: 77.14% | Test loss: 0.48375, Test acc: 77.60%\n",
      "Epoch: 9330 | Loss: 0.48467, Accuracy: 77.14% | Test loss: 0.48374, Test acc: 77.60%\n",
      "Epoch: 9340 | Loss: 0.48467, Accuracy: 77.14% | Test loss: 0.48374, Test acc: 77.60%\n",
      "Epoch: 9350 | Loss: 0.48466, Accuracy: 77.14% | Test loss: 0.48374, Test acc: 77.60%\n",
      "Epoch: 9360 | Loss: 0.48466, Accuracy: 77.14% | Test loss: 0.48373, Test acc: 77.60%\n",
      "Epoch: 9370 | Loss: 0.48466, Accuracy: 77.14% | Test loss: 0.48373, Test acc: 77.60%\n",
      "Epoch: 9380 | Loss: 0.48465, Accuracy: 77.14% | Test loss: 0.48372, Test acc: 77.60%\n",
      "Epoch: 9390 | Loss: 0.48465, Accuracy: 77.14% | Test loss: 0.48372, Test acc: 77.60%\n",
      "Epoch: 9400 | Loss: 0.48464, Accuracy: 77.14% | Test loss: 0.48372, Test acc: 77.60%\n",
      "Epoch: 9410 | Loss: 0.48464, Accuracy: 77.14% | Test loss: 0.48371, Test acc: 77.60%\n",
      "Epoch: 9420 | Loss: 0.48463, Accuracy: 77.14% | Test loss: 0.48371, Test acc: 77.60%\n",
      "Epoch: 9430 | Loss: 0.48463, Accuracy: 77.14% | Test loss: 0.48371, Test acc: 77.60%\n",
      "Epoch: 9440 | Loss: 0.48463, Accuracy: 77.15% | Test loss: 0.48370, Test acc: 77.62%\n",
      "Epoch: 9450 | Loss: 0.48462, Accuracy: 77.15% | Test loss: 0.48370, Test acc: 77.62%\n",
      "Epoch: 9460 | Loss: 0.48462, Accuracy: 77.15% | Test loss: 0.48369, Test acc: 77.62%\n",
      "Epoch: 9470 | Loss: 0.48461, Accuracy: 77.15% | Test loss: 0.48369, Test acc: 77.62%\n",
      "Epoch: 9480 | Loss: 0.48461, Accuracy: 77.15% | Test loss: 0.48369, Test acc: 77.62%\n",
      "Epoch: 9490 | Loss: 0.48460, Accuracy: 77.18% | Test loss: 0.48368, Test acc: 77.62%\n",
      "Epoch: 9500 | Loss: 0.48460, Accuracy: 77.18% | Test loss: 0.48368, Test acc: 77.62%\n",
      "Epoch: 9510 | Loss: 0.48460, Accuracy: 77.18% | Test loss: 0.48368, Test acc: 77.62%\n",
      "Epoch: 9520 | Loss: 0.48459, Accuracy: 77.18% | Test loss: 0.48367, Test acc: 77.62%\n",
      "Epoch: 9530 | Loss: 0.48459, Accuracy: 77.18% | Test loss: 0.48367, Test acc: 77.62%\n",
      "Epoch: 9540 | Loss: 0.48458, Accuracy: 77.18% | Test loss: 0.48367, Test acc: 77.62%\n",
      "Epoch: 9550 | Loss: 0.48458, Accuracy: 77.18% | Test loss: 0.48366, Test acc: 77.62%\n",
      "Epoch: 9560 | Loss: 0.48457, Accuracy: 77.19% | Test loss: 0.48366, Test acc: 77.62%\n",
      "Epoch: 9570 | Loss: 0.48457, Accuracy: 77.19% | Test loss: 0.48365, Test acc: 77.62%\n",
      "Epoch: 9580 | Loss: 0.48457, Accuracy: 77.19% | Test loss: 0.48365, Test acc: 77.62%\n",
      "Epoch: 9590 | Loss: 0.48456, Accuracy: 77.19% | Test loss: 0.48365, Test acc: 77.62%\n",
      "Epoch: 9600 | Loss: 0.48456, Accuracy: 77.19% | Test loss: 0.48364, Test acc: 77.62%\n",
      "Epoch: 9610 | Loss: 0.48455, Accuracy: 77.19% | Test loss: 0.48364, Test acc: 77.62%\n",
      "Epoch: 9620 | Loss: 0.48455, Accuracy: 77.19% | Test loss: 0.48364, Test acc: 77.62%\n",
      "Epoch: 9630 | Loss: 0.48454, Accuracy: 77.19% | Test loss: 0.48363, Test acc: 77.62%\n",
      "Epoch: 9640 | Loss: 0.48454, Accuracy: 77.19% | Test loss: 0.48363, Test acc: 77.62%\n",
      "Epoch: 9650 | Loss: 0.48454, Accuracy: 77.19% | Test loss: 0.48362, Test acc: 77.62%\n",
      "Epoch: 9660 | Loss: 0.48453, Accuracy: 77.19% | Test loss: 0.48362, Test acc: 77.62%\n",
      "Epoch: 9670 | Loss: 0.48453, Accuracy: 77.19% | Test loss: 0.48362, Test acc: 77.62%\n",
      "Epoch: 9680 | Loss: 0.48452, Accuracy: 77.19% | Test loss: 0.48361, Test acc: 77.62%\n",
      "Epoch: 9690 | Loss: 0.48452, Accuracy: 77.19% | Test loss: 0.48361, Test acc: 77.62%\n",
      "Epoch: 9700 | Loss: 0.48451, Accuracy: 77.19% | Test loss: 0.48361, Test acc: 77.62%\n",
      "Epoch: 9710 | Loss: 0.48451, Accuracy: 77.19% | Test loss: 0.48360, Test acc: 77.62%\n",
      "Epoch: 9720 | Loss: 0.48451, Accuracy: 77.19% | Test loss: 0.48360, Test acc: 77.62%\n",
      "Epoch: 9730 | Loss: 0.48450, Accuracy: 77.19% | Test loss: 0.48360, Test acc: 77.62%\n",
      "Epoch: 9740 | Loss: 0.48450, Accuracy: 77.19% | Test loss: 0.48359, Test acc: 77.62%\n",
      "Epoch: 9750 | Loss: 0.48449, Accuracy: 77.19% | Test loss: 0.48359, Test acc: 77.62%\n",
      "Epoch: 9760 | Loss: 0.48449, Accuracy: 77.19% | Test loss: 0.48358, Test acc: 77.62%\n",
      "Epoch: 9770 | Loss: 0.48448, Accuracy: 77.19% | Test loss: 0.48358, Test acc: 77.62%\n",
      "Epoch: 9780 | Loss: 0.48448, Accuracy: 77.19% | Test loss: 0.48358, Test acc: 77.62%\n",
      "Epoch: 9790 | Loss: 0.48448, Accuracy: 77.19% | Test loss: 0.48357, Test acc: 77.62%\n",
      "Epoch: 9800 | Loss: 0.48447, Accuracy: 77.19% | Test loss: 0.48357, Test acc: 77.62%\n",
      "Epoch: 9810 | Loss: 0.48447, Accuracy: 77.19% | Test loss: 0.48357, Test acc: 77.62%\n",
      "Epoch: 9820 | Loss: 0.48446, Accuracy: 77.19% | Test loss: 0.48356, Test acc: 77.62%\n",
      "Epoch: 9830 | Loss: 0.48446, Accuracy: 77.19% | Test loss: 0.48356, Test acc: 77.62%\n",
      "Epoch: 9840 | Loss: 0.48445, Accuracy: 77.19% | Test loss: 0.48356, Test acc: 77.62%\n",
      "Epoch: 9850 | Loss: 0.48445, Accuracy: 77.19% | Test loss: 0.48355, Test acc: 77.65%\n",
      "Epoch: 9860 | Loss: 0.48445, Accuracy: 77.19% | Test loss: 0.48355, Test acc: 77.65%\n",
      "Epoch: 9870 | Loss: 0.48444, Accuracy: 77.19% | Test loss: 0.48354, Test acc: 77.65%\n",
      "Epoch: 9880 | Loss: 0.48444, Accuracy: 77.19% | Test loss: 0.48354, Test acc: 77.65%\n",
      "Epoch: 9890 | Loss: 0.48443, Accuracy: 77.19% | Test loss: 0.48354, Test acc: 77.65%\n",
      "Epoch: 9900 | Loss: 0.48443, Accuracy: 77.19% | Test loss: 0.48353, Test acc: 77.65%\n",
      "Epoch: 9910 | Loss: 0.48443, Accuracy: 77.19% | Test loss: 0.48353, Test acc: 77.65%\n",
      "Epoch: 9920 | Loss: 0.48442, Accuracy: 77.19% | Test loss: 0.48353, Test acc: 77.65%\n",
      "Epoch: 9930 | Loss: 0.48442, Accuracy: 77.19% | Test loss: 0.48352, Test acc: 77.65%\n",
      "Epoch: 9940 | Loss: 0.48441, Accuracy: 77.19% | Test loss: 0.48352, Test acc: 77.65%\n",
      "Epoch: 9950 | Loss: 0.48441, Accuracy: 77.19% | Test loss: 0.48352, Test acc: 77.65%\n",
      "Epoch: 9960 | Loss: 0.48440, Accuracy: 77.19% | Test loss: 0.48351, Test acc: 77.65%\n",
      "Epoch: 9970 | Loss: 0.48440, Accuracy: 77.19% | Test loss: 0.48351, Test acc: 77.65%\n",
      "Epoch: 9980 | Loss: 0.48440, Accuracy: 77.19% | Test loss: 0.48350, Test acc: 77.62%\n",
      "Epoch: 9990 | Loss: 0.48439, Accuracy: 77.19% | Test loss: 0.48350, Test acc: 77.62%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Set the number of epochs\n",
    "epochs = 10000\n",
    "\n",
    "# Put data to target device\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "\n",
    "# Build training and evaluation loop\n",
    "for epoch in range(epochs):\n",
    "    ### Training\n",
    "    model_0.train()\n",
    "\n",
    "    # 1. Forward pass (model outputs raw logits)\n",
    "    y_logits = model_0(X_train).squeeze() # squeeze to remove extra `1` dimensions, this won't work unless model and data are on same device \n",
    "    y_pred = torch.round(torch.sigmoid(y_logits)) # turn logits -> pred probs -> pred labls\n",
    "  \n",
    "    # 2. Calculate loss/accuracy\n",
    "    # loss = loss_fn(torch.sigmoid(y_logits), # Using nn.BCELoss you need torch.sigmoid()\n",
    "    #                y_train) \n",
    "    loss = loss_fn(y_logits, # Using nn.BCEWithLogitsLoss works with raw logits\n",
    "                   y_train) \n",
    "    acc = accuracy_fn(y_true=y_train, \n",
    "                      y_pred=y_pred) \n",
    "\n",
    "    # 3. Optimizer zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backwards\n",
    "    loss.backward()\n",
    "\n",
    "    # 5. Optimizer step\n",
    "    optimizer.step()\n",
    "\n",
    "    # Append the loss value to the list\n",
    "    loss_values.append(loss.item())\n",
    "\n",
    "    ### Testing\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        # 1. Forward pass\n",
    "        test_logits = model_0(X_test).squeeze() \n",
    "        test_pred = torch.round(torch.sigmoid(test_logits))\n",
    "        # 2. Caculate loss/accuracy\n",
    "        test_loss = loss_fn(test_logits,\n",
    "                            y_test)\n",
    "        test_acc = accuracy_fn(y_true=y_test,\n",
    "                               y_pred=test_pred)\n",
    "\n",
    "    # Print out what's happening every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f}, Accuracy: {acc:.2f}% | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_values[1000:], label='Training Loss')\n",
    "plt.title('Training Loss Over Time')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure y_test and test_pred are on the CPU and converted to numpy arrays\u001b[39;00m\n\u001b[1;32m      5\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test \u001b[38;5;66;03m# Correctly convert to numpy\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure y_test and test_pred are on the CPU and converted to numpy arrays\n",
    "y_test = y_test # Correctly convert to numpy\n",
    "test_pred = test_pred  # Correctly convert to numpy\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 0.5889967637540453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Calculate the sensitivity\n",
    "sensitivity = recall_score(y_test, test_pred)\n",
    "\n",
    "# Print the sensitivity\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../modelin_model_0\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_path = Path(\"../models\\bin_model_0\")\n",
    "torch.save(model_0.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
